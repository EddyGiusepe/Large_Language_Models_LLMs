"""
Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro

An Introduction to OpenAI Function Calling
==========================================
Este script est√° baseado na publica√ß√£o de "David Hundley".

link de estudo --> https://towardsdatascience.com/an-introduction-to-openai-function-calling-e47e7cd7680e
"""
import openai
import json
import os
from dotenv import find_dotenv, load_dotenv
_ = load_dotenv(find_dotenv()) # read local .env file
openai.api_key  = os.getenv('OPENAI_API_KEY')

# Carregando o texto "Sobre mim" do arquivo local:
with open('./perfil_Eddy.txt', 'r') as f:
    sobre_mim = f.read()

print(sobre_mim)

"""Usando a API da OpenAI com um PROMPT
   ====================================
"""

# Criando um prompt para extrair o m√°ximo de informa√ß√µes de "Sobre mim" como um objeto JSON:
sobre_mim_prompt = f""" 
Por favor, extraia as informa√ß√µes como um objeto JSON. Por favor, procure as seguintes informa√ß√µes. 
Nome 
Cargo 
Empresa 
N√∫mero de filhos como um √∫nico inteiro 
Hobby
Onde estudou
Casado 

Este √© o corpo do texto para extrair as informa√ß√µes de: 
```{sobre_mim}```
""" 

# Usamo a API da OpenAI (ChatGPT - gpt-3.5-turbo)
openai_response = openai.ChatCompletion.create(model = 'gpt-3.5-turbo',
                                               messages = [{'role': 'user', 'content': sobre_mim_prompt}]
                                              )

# Carregando a resposta com um objeto JSON:
json_response = json.loads(openai_response['choices'][0]['message']['content'])
#print(json_response)


"""ü§ó Usando a API da OpenAI com Function Calling ü§ó
   =================================================
"""
# Definimos a nossa fun√ß√£o para extrair informa√ß√µes pessoais:
def extract_person_info(nome: str, cargo: str, casado: bool):
    '''
    Imprime informa√ß√µes b√°sicas "Sobre mim"

    Inputs:
        nome (str): Nome da pessoa
        cargo (str): profiss√£o da pessoa
        casado (bool): Se a pessoa √© casada.
    '''
    
    print(f'Esta pessoa se chama {nome}. O cargo dele √© {cargo}, e ele √© {casado}.')


# Definindo como queremos que o ChatGPT chame nossas fun√ß√µes personalizadas
my_custom_functions = [
    {
        'name': 'extract_person_info',
        'description': 'Obtenha informa√ß√µes "Sobre mim" do corpo do texto de entrada',
        'parameters': {
            'type': 'object',
            'properties': {
                'nome': {
                    'type': 'string',
                    'description': 'Nome da pessoa'
                },
                'cargo': {
                    'type': 'string',
                    'description': 'Profiss√£o da pessoa'
                },
                'casado': {
                    'type': 'boolean',
                    'description': 'Se a pessoa √© casada'
                }
            }
        }
    }
]


# Usando novamente a API da OpenAI:
openai_response = openai.ChatCompletion.create(model = 'gpt-3.5-turbo',
                                               messages = [{'role': 'user', 'content': sobre_mim}],
                                               functions = my_custom_functions,
                                               function_call = 'auto'
)

#print(openai_response)
print("ü§óü§óü§ó")
print(openai_response['choices'][0]["message"]["function_call"]["arguments"])


"""
Ent√£o, o que acontece quando enviamos um prompt que n√£o corresponde a nenhuma de nossas fun√ß√µes personalizadas? 
Simplificando, o padr√£o √© o comportamento t√≠pico, como se a chamada de fun√ß√£o n√£o existisse. 
Vamos testar isso com um prompt arbitr√°rio: "Qual √© a altura da Torre Eiffel?" üßê
"""

# Getting the response back from ChatGPT (gpt-3.5-turbo)
openai_response = openai.ChatCompletion.create(
    model = 'gpt-3.5-turbo',
    messages = [{'role': 'user', 'content': 'Qual √© a altura da Torre Eiffel?'}],
    functions = my_custom_functions,
    function_call = 'auto'
)

#print(openai_response)
json_response = openai_response['choices'][0]['message']['content']
print(json_response)
