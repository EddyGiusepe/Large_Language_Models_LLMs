{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><font color=\"yellow\">Engenharia de Prompt: O Mundo M√°gico dos Grandes Modelos de Linguagem</font></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">Data Scientist.: PhD.Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://marmof.com/storage/1561/S4qVfORqC6voHAjKUitH2bYHBfm1MS-metaVGhlIEFydCBvZiBQcm9tcHQgRW5naW5lZXJpbmcgKDEpLmpwZw==-.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">A arte e a ci√™ncia</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√â poss√≠vel combinar aprendizado de m√°quina com `Prompt Engineering` para grandes modelos de linguagem?\n",
    "\n",
    "Uma abordagem sistem√°tica baseada em dados para a engenharia de prompts pode ser uma das maneiras mais bem-sucedidas de gerar os melhores prompts.\n",
    "\n",
    "Neste script, o qual √© um resumo do artigo de [Kory Becker](), veremos exatamente como isso funciona medindo e pontuando diferentes prompts para tarefas de Processamento de Linguagem Natural (NLP)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Otimismo para tudo IA</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O potencial crescente de grandes modelos de linguagem, como o `ChatGPT`, tem impulsionado as empresas a trabalhar o mais r√°pido poss√≠vel para integrar a `IA` em seus produtos. De empresas a usu√°rios comuns, o potencial que vem da integra√ß√£o de grandes modelos de linguagem parece infinito.\n",
    "\n",
    "Juntamente com a explos√£o da inova√ß√£o de IA de `Transformers pr√©-treinados generativos` (GPT), surgiu uma especializa√ß√£o aparentemente m√≠stica, chamada `Engenharia de Prompt`.\n",
    "\n",
    "Bem, inicialmente fiquei c√©tico em rela√ß√£o a esse t√≠tulo emergente. Eu preferiria ver o uso corporativo significativo de grandes modelos de linguagem (por exemplo, `ChatGPT`) antes de criar a necessidade de uma carreira totalmente nova.\n",
    "\n",
    "No entanto, devo concordar que uma abordagem cuidadosa e cient√≠fica para a `Engenharia de Prompt`, medindo a produ√ß√£o, de fato, parece bastante promissora.\n",
    "\n",
    "Como tal, isso despertou meu interesse em `Engenharia de Prompt` para grandes modelos de linguagem, especialmente para tarefas de processamento de linguagem natural, e espero que esta t√©cnica tamb√©m inspire voc√™!\n",
    "\n",
    "Antes de fazermos alguma m√°gica, vamos mergulhar em uma defini√ß√£o de `Engenharia de Prompt`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">O que √© Engenharia de Prompt?</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Engenharia de Prompt` √© o nome dado ao processo de encontrar a melhor frase ou frase para perguntar a grandes modelos de linguagem, como o `ChatGPT`, a fim de obter a melhor resposta poss√≠vel.\n",
    "\n",
    "Embora os modelos de linguagem grandes sejam destinados √† comunica√ß√£o em estilo de conversa√ß√£o, os especialistas determinaram rapidamente que algumas perguntas funcionam melhor do que outras. √â esse processo de determinar quais palavras, declara√ß√µes e frases funcionam melhor para diferentes situa√ß√µes que forma o n√∫cleo por tr√°s da `Engenharia de Prompt`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">O que √© `Prompt`?</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Um Prompt √© a pergunta inicial feita a um modelo de linguagem grande`. O prompt define o tom, o conhecimento pr√©vio e geralmente inclui a pergunta central para um problema espec√≠fico.\n",
    "\n",
    "<font color=\"orange\">Abaixo est√£o alguns exemplos de prompts:</font>\n",
    "\n",
    ">Por favor, liste todas as datas do seguinte texto ‚Ä¶\n",
    "\n",
    ">Converta a seguinte lista de n√∫meros de telefone em n√∫meros de 7 d√≠gitos ‚Ä¶\n",
    "\n",
    ">Responda com sim ou n√£o se as hist√≥rias a seguir forem sobre a natureza ‚Ä¶"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Um Prompt precisa de conte√∫do</font>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al√©m de um `prompt`, tamb√©m precisamos de conte√∫do.\n",
    "\n",
    "Ao pedir a um grande modelo de linguagem para executar uma tarefa, alguma forma de conte√∫do √© normalmente fornecida para o modelo agir. `Pode ser texto, imagens, v√≠deo ou √°udio`.\n",
    "\n",
    "O conte√∫do pode ser inclu√≠do antes ou depois do `prompt`, mas geralmente √© anexado junto com o prompt e enviado para o modelo de linguagem grande como parte da conversa inicial.\n",
    "\n",
    "Ao incluir um prompt e conte√∫do, podemos consultar uma resposta.\n",
    "\n",
    "√â essa metodologia central que nos permite recuperar uma resposta v√°lida e precisa, que completa o of√≠cio chamado `Engenharia de Prompt`.\n",
    "\n",
    "ü•π Claro, a `Engenharia de Prompt` n√£o vem sem suas dificuldades. ü•π"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Sensibilidade do fraseado</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos de linguagem grandes geralmente s√£o `muito sens√≠veis a pequenas mudan√ßas na reda√ß√£o das perguntas`.\n",
    "\n",
    "Uma √∫nica altera√ß√£o em uma palavra, emo√ß√£o ou tom de um prompt pode afetar substancialmente a resposta de um grande modelo de linguagem. Por esta raz√£o, um meio de medir e avaliar o desempenho de um prompt √© uma necessidade.\n",
    "\n",
    "Pode ser conveniente usar uma estimativa aproximada para determinar se um prompt espec√≠fico √© eficaz. No entanto, podemos fazer muito melhor!\n",
    "\n",
    "`S√≥ √© preciso um pouco de matem√°tica`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">O bom e velho aprendizado de m√°quina</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere a tarefa de executar Processamento de Linguagem Natural (NLP) ou classifica√ß√£o de texto.\n",
    "\n",
    "Os problemas de NLP geralmente s√£o processados ‚Äã‚Äãpor modelos tradicionais de aprendizado de m√°quina, como `regress√£o log√≠stica`, `m√°quinas de vetores de suporte` ou `aprendizado profundo` (Deep Learning).\n",
    "\n",
    "Como o aprendizado de m√°quina √© uma abordagem baseada em estat√≠stica para intelig√™ncia artificial, os modelos criados usando esse m√©todo v√™m com estat√≠sticas de precis√£o resultantes, incluindo `precision`, `recall` e `overall accuracy`. Esses n√∫meros s√£o calculados observando o n√∫mero de `positivos` e `negativos` corretos que resultam das previs√µes do modelo em um conjunto de treinamento.\n",
    "\n",
    "<font color=\"orange\">A quest√£o √©: isso tamb√©m pode ser feito com `Engenharia de prompt`?</font>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Modelos de linguagem grandes j√° s√£o inteligentes, certo?</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os usu√°rios est√£o obtendo resultados promissores conversando com grandes modelos de linguagem para fazer perguntas sobre uma variedade de t√≥picos.\n",
    "\n",
    "Grandes modelos de linguagem j√° foram projetados para fazer isso. Ent√£o, `h√° algo para realmente treinar?`\n",
    "\n",
    "Bem, como se v√™, tamb√©m √© poss√≠vel usar grandes modelos de linguagem para `classifica√ß√£o`, `reconhecimento` e outras tarefas preditivas. Isso √© diferente de uma simples conversa; no sentido de que estamos interessados ‚Äã‚Äãem obter sa√≠das espec√≠ficas para um grande n√∫mero de exemplos de treinamento.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Modelos preditivos</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplos de modelos preditivos podem incluir `An√°lise de Sentimento`, `reconhecimento de imagem`, `detec√ß√£o emocional`, `extra√ß√£o de frase` ou outros tipos de identifica√ß√£o.\n",
    "\n",
    "Essas tarefas t√™m sido tradicionalmente executadas com um conjunto de treinamento conhecido, contendo conte√∫do juntamente com respostas conhecidas. Um modelo de aprendizado de m√°quina √© treinado nesses dados e pode fazer previs√µes sobre novos dados que ainda n√£o viu.\n",
    "\n",
    "Esta √© a chave para a aprendizagem supervisionada.\n",
    "\n",
    "√â claro que, quando se trata de modelos de linguagem grandes com IU de conversa√ß√£o, n√£o √© assim que eles costumam ser usados ‚Äã‚Äã‚Äî pelo menos n√£o pelo usu√°rio comum.\n",
    "\n",
    "No entanto, combinando a abordagem `supervisionada` do aprendizado de m√°quina com a `Engenharia de Prompt` em modelos de linguagem grandes, podemos projetar uma solu√ß√£o preditiva de alta `Accuracy`.\n",
    "\n",
    "Vamos dar uma olhada em como isso funciona."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Construindo um modelo para medir a `\"raiva\"`</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere o caso de classificar uma s√©rie de senten√ßas como expressando a `emo√ß√£o da raiva`.\n",
    "\n",
    "Queremos construir um modelo para responder com `‚Äúsim‚Äù `se a frase expressar `raiva` e `‚Äún√£o‚Äù` caso contr√°rio.\n",
    "\n",
    "Criaremos um conjunto de treinamento com um grande n√∫mero de frases, como `an√°lises de produtos`, e enviaremos cada uma delas, junto com um `prompt`, para o modelo de linguagem grande (<font color=\"red\">por exempl:</font> a `API ChatGPT`) para obter um resultado de classifica√ß√£o.\n",
    "\n",
    "Um exemplo do que podemos perguntar ao modelo √© mostrado abaixo.\n",
    "\n",
    "```\n",
    "A frase √© sobre raiva? Responda apenas com a palavra ‚Äúsim‚Äù ou ‚Äún√£o‚Äù.\n",
    "```\n",
    "\n",
    "Agora, pode muito bem ser poss√≠vel que esse `prompt` retorne um resultado que pare√ßa bom. No entanto, `vamos medir o resultado usando v√°rios prompts diferentes` em todo o conjunto de treinamento, a fim de obter a maior accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">`Etapa 1:` Construir um conjunto de treinamento\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos come√ßar criando um conjunto de dados de treinamento. Cada linha de exemplo no conjunto de treinamento conter√° um valor de `‚Äúverdade‚Äù` (truth), indicando `1` ou `0` se a frase for sobre `raiva`.\n",
    "\n",
    "Um exemplo deste conjunto de treinamento √© mostrado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [ \n",
    " {'content': 'Eu odeio essa comida.', 'truth': 0},\n",
    " {'content': 'Este filme √© terr√≠vel.', 'truth': 1},\n",
    " {'content': 'Eu n√£o posso acreditar que voc√™ faria algo assim!', 'truth': 1},\n",
    " {'content': 'Isso √© absolutamente inaceit√°vel!', 'truth': 1},\n",
    " {'content': 'Estou com tanta raiva agora que nem consigo pensar direito.', 'truth': 1},\n",
    " {'content': 'Como voc√™ pode ser t√£o imprudente?', 'truth': 1},\n",
    " {'content': 'Voc√™ n√£o tem ideia do quanto me machucou.', 'truth': 1},\n",
    " {'content': 'Eu realmente gosto desta pe√ßa.', 'truth': 0},\n",
    " {'content': 'Eu simplesmente n√£o tenho certeza.', 'truth': 0},\n",
    " {'content': 'Est√° um lindo dia l√° fora.', 'truth': 0},\n",
    " {'content': 'Estou ansioso pelas minhas f√©rias na pr√≥xima semana.', 'truth': 0},\n",
    " {'content': 'O novo restaurante da cidade tem comida incr√≠vel.', 'truth': 0}\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando esse conjunto de treinamento, podemos pegar um `prompt` e combin√°-lo com a frase para enviar ao modelo de linguagem grande para obter uma resposta.\n",
    "\n",
    "O resultado do modelo pode ser comparado com o valor `verdadeiro` (truth) e adicionado √† pontua√ß√£o geral da accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Um prompt, dois prompts, tr√™s prompts, quatro</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para otimizar os resultados, podemos repetir o processo de treinamento usando `v√°rios prompts diferentes`.\n",
    "\n",
    "Cada `prompt` ser√° anexado a cada frase do conjunto de treinamento e enviado ao modelo de linguagem grande para uma resposta.\n",
    "\n",
    "Como veremos em breve, √© `muito prov√°vel que pequenas diferen√ßas nos prompts produzam sa√≠das diferentes para os registros`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">`Etapas 2:` chame a API ChatGPT</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo est√° um exemplo de chamada da `API ChatGPT`. Isso formar√° nosso principal m√©todo de comunica√ß√£o para chamar o servi√ßo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # Este √© o grau de aleatoriedade da sa√≠da do modelo\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">`Etapa 3:` prever um resultado</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre-se de que nosso m√©todo envolve anexar um `prompt` com uma frase de nosso conjunto de dados. Portanto, precisaremos de um m√©todo para iterar sobre cada item do array `‚Äúmessages‚Äù`, acrescentando o `prompt` a cada um e enviando o prompt mais o conte√∫do para o modelo de linguagem grande.\n",
    "\n",
    "Um exemplo de m√©todo de previs√£o √© mostrado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prompt):\n",
    "    y_pred = []\n",
    "    \n",
    "    for message in messages:\n",
    "        # Anexe o prompt e a frase (sentence) e envie para o ChatGPT.\n",
    "        payload = prompt + ' ```' + message['content'] + '```'\n",
    "        response = get_completion(payload)\n",
    "\n",
    "        # Salve a resposta prevista.\n",
    "        y_pred.append(1 if 'sim' in response.lower() else 0)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No c√≥digo acima, estamos armazenando as previs√µes de resposta em uma `matriz` (array) denominada `‚Äúy_pred‚Äù`. Esses valores podem ent√£o ser comparados com os valores de verdade (truth) para cada item no conjunto de treinamento para construir uma `matriz de confus√£o` e `pontua√ß√£o de accuracy`.\n",
    "\n",
    "Vamos ver como nosso `prompt` est√° realmente executando ao calcular esses valores.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">A matriz de confus√£o, precis√£o, recall e F-score</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para construir uma `matriz de confus√£o` e uma pontua√ß√£o de `accuracy`, precisaremos contar quantas respostas correspondem aos valores verdadeiros de cada item de treinamento.\n",
    "\n",
    "O c√≥digo modificado para nosso m√©todo de previs√£o √© mostrado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prompt):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    responses = []\n",
    "    \n",
    "    for message in messages:\n",
    "        # Append the prompt and sentence and send to ChatGPT.\n",
    "        payload = prompt + ' ```' + message['content'] + '```'\n",
    "        response = get_completion(payload)\n",
    "\n",
    "        # Append the truth value and the predicted response.\n",
    "        y_true.append(message['truth'])\n",
    "        y_pred.append(1 if 'sim' in response.lower() else 0)\n",
    "\n",
    "        responses.append(response)\n",
    "\n",
    "    # Initialize the confusion matrix\n",
    "    cm = [[0, 0], [0, 0]]\n",
    "\n",
    "    # Populate the confusion matrix\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        cm[true_label][pred_label] += 1\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    for row in cm:\n",
    "        print(row)\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    #precision = cm[1][1] / (cm[1][1] + cm[0][1])\n",
    "    precision = cm[1][1] / (cm[1][1] + cm[0][1]) if (cm[1][1] + cm[0][1]) != 0 else 0.0\n",
    "\n",
    "    recall = cm[1][1] / (cm[1][1] + cm[1][0])\n",
    "\n",
    "    # Calculate the F-score\n",
    "    #f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    if (precision + recall) != 0:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f_score = 0.0\n",
    "\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = (cm[0][0] + cm[1][1]) / sum(map(sum, cm))\n",
    "\n",
    "    return { 'f_score': f_score, 'accuracy': accuracy, 'truth': y_true, 'predicted': y_pred, 'responses': responses }\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que preenchemos manualmente uma `matriz de confus√£o` comparando o `valor verdadeiro` de cada item do conjunto de dados com o resultado da resposta do `ChatGPT`.\n",
    "\n",
    "Usando os n√∫meros resultantes, tamb√©m podemos calcular a `precision`, `recall`, `F-score` e a `accuracy` geral.\n",
    "\n",
    "Um exemplo de execu√ß√£o do m√©todo de previs√£o com um `prompt` √© mostrado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 1]\n",
      "[0, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f_score': 0.923076923076923,\n",
       " 'accuracy': 0.9166666666666666,\n",
       " 'truth': [0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       " 'predicted': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       " 'responses': ['sim',\n",
       "  'sim',\n",
       "  'Sim.',\n",
       "  'Sim.',\n",
       "  'sim',\n",
       "  'Sim.',\n",
       "  'Sim.',\n",
       "  'N√£o.',\n",
       "  'N√£o.',\n",
       "  'N√£o.',\n",
       "  'N√£o.',\n",
       "  'N√£o.']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"\"\"Determine se a seguinte frase entre crases \\\n",
    "        cont√©m um sentimento de raiva, repulsa ou negatividade. \\\n",
    "        Responda apenas com a palavra \"sim\" ou \"n√£o\".\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
