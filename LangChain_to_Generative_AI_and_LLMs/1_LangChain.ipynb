{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><font color=\"yellow\">LangChain 1: GPT-3 vs LLMs (c√≥digo aberto)</font></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste script seguiremos os tutoriais de [James Briggs](https://www.pinecone.io/learn/langchain-intro/) üòé."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualizando"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LangChain` √© um Framework popular que permite aos usu√°rios criar rapidamente aplicativos e pipelines em torno de `Large Language Models` (LLMs). Ele se integra diretamente aos modelos `GPT-3` e `GPT-3.5` da `OpenAI` e √†s alternativas de c√≥digo aberto do `Hugging Face`, como os modelos `flan-t5 do Google`. Ele pode ser usado para `chatbots`, `perguntas-respostas generativas` (GQA), `resumos` e muito mais. A ideia central da biblioteca √© que podemos `\"encadear\"` (chain) diferentes componentes para criar casos de uso mais avan√ßados em torno de LLMs. As cadeias podem consistir em v√°rios componentes de v√°rios m√≥dulos. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdu√ß√£o"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come√ßamos citando e descrevendo as quatro componentes b√°sicas:\n",
    "\n",
    "* `Prompt templates:` Os templates de prompt s√£o, bem, modelos para diferentes tipos de prompts. Como modelos de estilo `\"chatbot\"`, respostas a perguntas `ELI5`, etc.\n",
    "\n",
    "* `LLMs:` Modelos de Linguagem Grandes como `GPT-3`, `BLOOM`, etc.\n",
    "\n",
    "* `Agentes:` os agentes usam LLMs para decidir quais a√ß√µes devem ser executadas, ferramentas como pesquisa na Web ou calculadoras podem ser usadas e tudo empacotado em um loop l√≥gico de opera√ß√µes.\n",
    "\n",
    "* `Mem√≥ria:` mem√≥ria de curto prazo, mem√≥ria de longo prazo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando a minha chave Key:  True\n"
     ]
    }
   ],
   "source": [
    "# Isto √© quando usas o arquivo .env:\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "print('Carregando a minha chave Key: ', load_dotenv())\n",
    "Eddy_API_KEY_OpenAI = os.environ['OPENAI_API_KEY'] \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando LLMs em LangChain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">O LangChain oferece suporte a v√°rios provedores de LLM, como Hugging Face e OpenAI.\n",
    "\n",
    "Vamos come√ßar nossa explora√ß√£o do LangChain aprendendo como usar algumas dessas diferentes integra√ß√µes LLM.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e1f61a9d800d8d7b3909976e7b91d21ea533d3244cb881687ab788269722b79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
