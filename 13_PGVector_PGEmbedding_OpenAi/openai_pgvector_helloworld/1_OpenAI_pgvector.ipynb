{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><font color=\"yellow\">PGVector: Crie, armazene e consulte Embeddings OpenAI no PostgreSQL usando pgvector</font></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vamos aprender:\n",
    "\n",
    "* Como usar o `PostgreSQL` como um banco de dados vetorial e armazenar dados de embeddings nele usando pgvector.\n",
    "\n",
    "* Como usar Embeddings recuperadas (retrieved) de um banco de dados de vetores para aumentar a geração de LLM.\n",
    "\n",
    "\n",
    "Usaremos o exemplo de criação de um chatbot para responder a perguntas sobre casos de uso do Timescale, fazendo referência ao conteúdo das postagens do blog Timescale Developer Q+A.\n",
    "\n",
    "Este é um ótimo primeiro passo para criar algo como um chatbot que pode fazer referência a uma base de conhecimento da empresa ou a documentos do desenvolvedor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link de estudo:\n",
    "\n",
    "* [pgvector](https://github.com/timescale/vector-cookbook/blob/main/openai_pgvector_helloworld/openai_pgvector_helloworld.ipynb)\n",
    "\n",
    "* [LangChain and PGVector](https://github.com/timescale/vector-cookbook/blob/main/intro_langchain_pgvector/langchain_pgvector_intro.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"pink\">Não esqueça de rodar a Imagem de `pgvector`:</font>\n",
    "\n",
    "* docker pull ankane/pgvector\n",
    "\n",
    "* docker-compose up -d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.0.184\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://www.github.com/hwchase17/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/eddygiusepe/1_Eddy_Giusepe/3_estudando_LLMs/Large_Language_Models_LLMs/venv_LLMs/lib/python3.10/site-packages\n",
      "Requires: aiohttp, async-timeout, dataclasses-json, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain-experimental\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 0.27.6\n",
      "Summary: Python client library for the OpenAI API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: OpenAI\n",
      "Author-email: support@openai.com\n",
      "License: \n",
      "Location: /home/eddygiusepe/1_Eddy_Giusepe/3_estudando_LLMs/Large_Language_Models_LLMs/venv_LLMs/lib/python3.10/site-packages\n",
      "Requires: aiohttp, requests, tqdm\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: <font color=\"red\">Criamos os Embeddings</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CloudQuery on Using PostgreSQL for Cloud Asset...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/cloudquery-on-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How a Data Scientist Is Building a Time-Series...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-a-data-scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How Conserv Safeguards History: Building an En...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-conserv-saf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Messari Uses Data to Open the Cryptoeconom...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-messari-use...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  How to Build a Weather Station With Elixir, Ne...   \n",
       "1  CloudQuery on Using PostgreSQL for Cloud Asset...   \n",
       "2  How a Data Scientist Is Building a Time-Series...   \n",
       "3  How Conserv Safeguards History: Building an En...   \n",
       "4  How Messari Uses Data to Open the Cryptoeconom...   \n",
       "\n",
       "                                             content  \\\n",
       "0  This is an installment of our “Community Membe...   \n",
       "1  This is an installment of our “Community Membe...   \n",
       "2  This is an installment of our “Community Membe...   \n",
       "3  This is an installment of our “Community Membe...   \n",
       "4  This is an installment of our “Community Membe...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.timescale.com/blog/how-to-build-a-...  \n",
       "1  https://www.timescale.com/blog/cloudquery-on-u...  \n",
       "2  https://www.timescale.com/blog/how-a-data-scie...  \n",
       "3  https://www.timescale.com/blog/how-conserv-saf...  \n",
       "4  https://www.timescale.com/blog/how-messari-use...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tiktoken\n",
    "import psycopg2\n",
    "import ast\n",
    "import pgvector\n",
    "import math\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "\n",
    "# Load your CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('blog_posts_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Build a Weather Station With Elixir, Nerves, and TimescaleDB\n",
      "\n",
      "This is an installment of our “Community Member Spotlight” series, where we invite our customers to share their work, shining a light on their success and inspiring others with new ways to use technology to solve problems.In this edition,Alexander Koutmos, author of the Build a Weather Station with Elixir and Nerves book, joins us to share how he uses Grafana and TimescaleDB to store and visualize weather data collected from IoT sensors.About the teamThe bookBuild a Weather Station with Elixir and Nerveswas a joint effort between Bruce Tate, Frank Hunleth, and me.I have been writing software professionally for almost a decade and have been working primarily with Elixir since 2016. I currently maintain a few Elixir libraries onHexand also runStagira, a software consultancy company.Bruce Tateis a kayaker, programmer, and father of two from Chattanooga, Tennessee. He is the author of more than ten books and has been around Elixir from the beginning. He is the founder ofGroxio, a company that trains Elixir developers.Frank Hunlethis an embedded systems programmer, OSS maintainer, and Nerves core team member. When not in front of a computer, he loves running and spending time with his family.About the projectIn the Pragmatic Bookshelf book,Build a Weather Station with Elixir and Nerves, we take a project-based approach and guide the reader to create a Nerves-powered IoT weather station.For those unfamiliar with the Elixir ecosystem,Nervesis an IoT framework that allows you to build and deploy IoT applications on a wide array of embedded devices. At a high level, Nerves allows you to focus on building your project and takes care of a lot of the boilerplate associated with running Elixir on embedded devices.The goal of the book is to guide the reader through the process of building an end-to-end IoT solution for capturing, persisting, and visualizing weather data.Assembled weather station hooked up to development machine.One of the motivating factors for this book was to create a real-world project where readers could get hands-on experience with hardware without worrying too much about the nitty-gritty of soldering components together. Experimenting with hardware can often feel intimidating and confusing, but with Elixir and Nerves, we feel confident that even beginners get comfortable and productive quickly. As a result, in the book, we leverage a Raspberry Pi Zero W along with a few I2C enabled sensors to capture weather and environmental data. In all, the reader will capture and persist into TimescaleDB the current: altitude, atmospheric pressure, temperature, CO2 levels,TVOClevels, and the ambient light.Once the environmental data is captured on the Nerves device, it is published to a backend REST API and stored in TimescaleDB for later analytics/visualization. Luckily, TimescaleDB is an extension on top of PostgreSQL, allowing Elixir developers to use existing database tooling likeEctoto interface with time-series enabled tables.After the time-series weather data is stored in TimescaleDB, we walk the reader through how to visualize this data using the popular open-source visualization toolGrafana.Using Grafana for visualizing the weather was an easy choice given that Grafana natively supports TimescaleDB and is able to easily plot time-series data stored in TimescaleDB hypertables.✨Editor’s Note:Check outGrafana 101 video seriesandGrafana tutorialsto learn everything from building awesome, interactive visualizations to setting up custom alerts, sharing dashboards with teammates, and solving common issues.The diagram shows all of the various components of the weather station system and how they interact with one another.By the end of the book, readers have a fully-featured IoT application and API backend that can power a live Grafana dashboard in order to plot their TimescaleDB data published from their Nerves weather station.Screenshot of Grafana dashboard, showing various graphs for various weather data📖If you are interested in learning about how to build an end-to-end IoT weather monitoring solution, be sure tocheck out the book and the accompanying code. If you are interested in learning more about Nerves and Elixir,check out the Nerves documentation.Choosing (and using!) TimescaleDBFrom the onset of the book, we knew that we wanted to use a purpose-built time-series database to persist the weather station data. We wanted the project to be as realistic as possible and something that could possibly be expanded for use in the real world.With that goal in mind, TimescaleDB was an obvious choice given that PostgreSQL has become a ubiquitous database and it has great support in the Elixir community. In addition,leveraging TimescaleDB on top of PostgreSQL does not add a tremendous amount of overhead or complexity and allows new users to easily leverage the benefits of a time-series database without having to learn any new query languages or databases. Specifically, all it took for readers to start leveraging TimescaleDB was to run a single SQL command in their database migration:SELECT create_hypertable('weather_conditions', 'timestamp').\"It’s this kind of pragmatism and ease of use that makes TimescaleDB a great time-series database for projects both small and large. \"-Alexander KoutmousAll in all, leveraging TimescaleDB as the time-series database for the project worked out great and allowed us to show readers how they can set up a production-ready IoT project in a relatively short amount of time.✨Editor’s Note:To start with TimescaleDB today,sign up for a free 30-day trialorinstall TimescaleDB on your own server.Getting started advice & resourcesAny time we had questions about the inner workings of TimescaleDB, how to set it up, or what the various configuration options are, we turned to the official TimescaleDB docs. Some of the articles that helped us get started included:•Using TimescaleDB via Docker• Understanding some ofthe fundamental TimescaleDB concepts• Getting an overview of some of theTimescaleDB best practicesWe’d like to thank Alex, Bruce, and Frank for sharing their story, as well as for writing a book that makes building full-stack IoT solutions accessible for complete beginners. We congratulate them and the entire Nerves community on their success, and we cannot wait to read the final version of their book that will be released in January 2022 🎊We’re always keen to feature new community projects and stories on our blog. If you have a story or project you’d like to share, reach out on Slack (@Lucie Šimečková), and we’ll go from there.Additionally, if you’re looking for more ways to get involved and show your expertise, check out theTimescaleHeroes program.The open-source relational database for time-series and analytics.Try Timescale for free\n",
      "\n",
      "https://www.timescale.com/blog/how-to-build-a-weather-station-with-elixir-nerves-and-timescaledb/\n"
     ]
    }
   ],
   "source": [
    "print(df['title'].iloc[0])\n",
    "print(\"\")\n",
    "print(df['content'].iloc[0])\n",
    "print(\"\")\n",
    "print(df['url'].iloc[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Calculamos o custo de Embeddings de nosso Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Geralmente, é uma boa ideia calcular quanto custará a criação de Embeddings para o conteúdo selecionado. Usamos várias funções auxiliares para calcular uma estimativa de custo antes de criar as incorporações para nos ajudar a evitar surpresas.\n",
    "\n",
    "Para este exemplo de brinquedo, como estamos usando um pequeno conjunto de dados, o custo total será inferior a `US$ 0,01.`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to help us create the embeddings\n",
    "\n",
    "# Helper func: calculate number of tokens\n",
    "def num_tokens_from_string(string: str, encoding_name = \"cl100k_base\") -> int:\n",
    "    if not string:\n",
    "        return 0\n",
    "    # Returns the number of tokens in a text string\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "# Helper function: calculate length of essay\n",
    "def get_essay_length(essay):\n",
    "    word_list = essay.split()\n",
    "    num_words = len(word_list)\n",
    "    return num_words\n",
    "\n",
    "# Helper function: calculate cost of embedding num_tokens\n",
    "# Assumes we're using the text-embedding-ada-002 model\n",
    "# See https://openai.com/pricing\n",
    "def get_embedding_cost(num_tokens):\n",
    "    return num_tokens/1000*0.0001\n",
    "\n",
    "# Helper function: calculate total cost of embedding all content in the dataframe\n",
    "def get_total_embeddings_cost():\n",
    "    total_tokens = 0\n",
    "    for i in range(len(df.index)):\n",
    "        text = df['content'][i]\n",
    "        token_len = num_tokens_from_string(text)\n",
    "        total_tokens = total_tokens + token_len\n",
    "    total_cost = get_embedding_cost(total_tokens)\n",
    "    return total_cost\n",
    "\n",
    "# Helper function: get embeddings for a text\n",
    "def get_embeddings(text):\n",
    "    response = openai.Embedding.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input = text.replace(\"\\n\",\" \")\n",
    "    )\n",
    "    embedding = response['data'][0]['embedding']\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preço estimado para Embeddings deste conteúdo = $0.0060178\n"
     ]
    }
   ],
   "source": [
    "# verificação rápida do valor total do token para estimativa de preço\n",
    "total_cost = get_total_embeddings_cost()\n",
    "print(\"Preço estimado para Embeddings deste conteúdo = $\" + str(total_cost))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Criamos chunks menores de conteúdo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A API OpenAI tem um limite para a quantidade máxima de `tokens` que ela cria para criar um Embedding em uma única solicitação. Para contornar esse limite, vamos dividir nosso texto em partes menores. Em geral, é uma prática recomendada criar embeddings de um determinado tamanho para obter uma melhor recuperação. Para nossos propósitos, buscaremos pedaços de cerca de `512` tokens cada.\n",
    "\n",
    "<font color=\"red\">NOTA:</font>\n",
    "\n",
    "se preferir pular esta etapa, você pode usar o arquivo fornecido: `blog_data_and_embeddings.csv`, que contém os dados e Embeddings que você gerará nesta etapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Crie uma nova lista com pequenos chunks de conteúdo para não atingir os limites máximos de token\n",
    "# Note: o número máximo de tokens para uma única solicitação é 8191\n",
    "# https://openai.com/docs/api-reference/requests\n",
    "###############################################################################\n",
    "# list for chunked content and embeddings\n",
    "new_list = []\n",
    "# Divida o texto em tamanhos de token de cerca de 512 tokens\n",
    "for i in range(len(df.index)):\n",
    "    text = df['content'][i]\n",
    "    token_len = num_tokens_from_string(text)\n",
    "    if token_len <= 512:\n",
    "        new_list.append([df['title'][i], df['content'][i], df['url'][i], token_len])\n",
    "    else:\n",
    "        # add content to the new list in chunks\n",
    "        start = 0\n",
    "        ideal_token_size = 512\n",
    "        # 1 token ~ 3/4 of a word\n",
    "        ideal_size = int(ideal_token_size // (4/3))\n",
    "        end = ideal_size\n",
    "        #split text by spaces into words\n",
    "        words = text.split()\n",
    "\n",
    "        #remove empty spaces\n",
    "        words = [x for x in words if x != ' ']\n",
    "\n",
    "        total_words = len(words)\n",
    "        \n",
    "        #calculate iterations\n",
    "        chunks = total_words // ideal_size\n",
    "        if total_words % ideal_size != 0:\n",
    "            chunks += 1\n",
    "        \n",
    "        new_content = []\n",
    "        for j in range(chunks):\n",
    "            if end > total_words:\n",
    "                end = total_words\n",
    "            new_content = words[start:end]\n",
    "            new_content_string = ' '.join(new_content)\n",
    "            new_content_token_len = num_tokens_from_string(new_content_string)\n",
    "            if new_content_token_len > 0:\n",
    "                new_list.append([df['title'][i], new_content_string, df['url'][i], new_content_token_len])\n",
    "            start += ideal_size\n",
    "            end += ideal_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>501</td>\n",
       "      <td>[0.021440856158733368, 0.02200360782444477, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>capture weather and environmental data. In all...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>512</td>\n",
       "      <td>[0.01620873250067234, 0.011362895369529724, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>command in their database migration:SELECT cre...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>374</td>\n",
       "      <td>[0.022517921403050423, -0.0019158280920237303,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CloudQuery on Using PostgreSQL for Cloud Asset...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/cloudquery-on-u...</td>\n",
       "      <td>519</td>\n",
       "      <td>[0.008915113285183907, -0.004873732570558786, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CloudQuery on Using PostgreSQL for Cloud Asset...</td>\n",
       "      <td>Architecture with CloudQuery SDK- Writing plug...</td>\n",
       "      <td>https://www.timescale.com/blog/cloudquery-on-u...</td>\n",
       "      <td>511</td>\n",
       "      <td>[0.0204352755099535, 0.010087345726788044, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  How to Build a Weather Station With Elixir, Ne...   \n",
       "1  How to Build a Weather Station With Elixir, Ne...   \n",
       "2  How to Build a Weather Station With Elixir, Ne...   \n",
       "3  CloudQuery on Using PostgreSQL for Cloud Asset...   \n",
       "4  CloudQuery on Using PostgreSQL for Cloud Asset...   \n",
       "\n",
       "                                             content  \\\n",
       "0  This is an installment of our “Community Membe...   \n",
       "1  capture weather and environmental data. In all...   \n",
       "2  command in their database migration:SELECT cre...   \n",
       "3  This is an installment of our “Community Membe...   \n",
       "4  Architecture with CloudQuery SDK- Writing plug...   \n",
       "\n",
       "                                                 url  tokens  \\\n",
       "0  https://www.timescale.com/blog/how-to-build-a-...     501   \n",
       "1  https://www.timescale.com/blog/how-to-build-a-...     512   \n",
       "2  https://www.timescale.com/blog/how-to-build-a-...     374   \n",
       "3  https://www.timescale.com/blog/cloudquery-on-u...     519   \n",
       "4  https://www.timescale.com/blog/cloudquery-on-u...     511   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.021440856158733368, 0.02200360782444477, -0...  \n",
       "1  [0.01620873250067234, 0.011362895369529724, 0....  \n",
       "2  [0.022517921403050423, -0.0019158280920237303,...  \n",
       "3  [0.008915113285183907, -0.004873732570558786, ...  \n",
       "4  [0.0204352755099535, 0.010087345726788044, 0.0...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crie Embeddings para cada parte do conteúdo:\n",
    "for i in range(len(new_list)):\n",
    "    text = new_list[i][1]\n",
    "    embedding = get_embeddings(text)\n",
    "    new_list[i].append(embedding)\n",
    "\n",
    "# Create a new dataframe from the list\n",
    "df_new = pd.DataFrame(new_list, columns=['title', 'content', 'url', 'tokens', 'embeddings'])\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salve o dataframe com incorporações como um arquivo CSV\n",
    "df_new.to_csv('blog_data_and_embeddings.csv', index=False)\n",
    "\n",
    "# Também pode ser útil salvar como um arquivo JSON, mas não usaremos isso no tutorial\n",
    "#df_new.to_json('blog_data_and_embeddings.json')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2: <font color=\"red\">Armazenar Embeddings com pgvector</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, armazenaremos nossos Embeddings e metadados associados.\n",
    "\n",
    "Usaremos o `PostgreSQL` como banco de dados vetorial, com a extensão `pgvector`.\n",
    "\n",
    "Você pode criar um banco de dados PostgreSQL em nuvem gratuitamente no Timescale ou usar um banco de dados PostgreSQL local para esta etapa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Conecte-se e configure seu vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timescale database connection string\n",
    "# Found under \"Service URL\" of the credential cheat-sheet or \"Connection Info\" in the Timescale console\n",
    "# In terminal, run: export TIMESCALE_CONNECTION_STRING=postgres://<fill in here>\n",
    "\n",
    "import psycopg2\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "\n",
    "# Constrói a string de conexão PGVector a partir dos parâmetros.\n",
    "host= os.environ['DB_HOST']\n",
    "port= os.environ['DB_PORT']\n",
    "user= os.environ['DB_USER']\n",
    "password= os.environ['DB_PASSWORD']\n",
    "dbname= os.environ['DB_NAME']\n",
    "\n",
    "# Usamos postgresql em vez de postgres na string conn, já que LangChain usa sqlalchemy sob o capô\n",
    "# Você pode remover o ?sslmode=require se tiver uma instância local do PostgreSQL rodando sem SSL\n",
    "\n",
    "#CONNECTION_STRING = f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{dbname}?sslmode=require\"\n",
    "CONNECTION_STRING = f\"postgresql://{user}:{password}@{host}:{port}/{dbname}\"\n",
    "#connection_string  = os.environ['TIMESCALE_CONNECTION_STRING'] \n",
    "\n",
    "# Connect to PostgreSQL database in Timescale using connection string\n",
    "conn = psycopg2.connect(CONNECTION_STRING)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Install pgvector \n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\");\n",
    "conn.commit()\n",
    "\n",
    "# Register the vector type with psycopg2\n",
    "register_vector(conn)\n",
    "\n",
    "# Criar tabela para armazenar embeddings e metadados (metadata):\n",
    "table_create_command = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Tabela_Eddy_Embeddings (\n",
    "            id bigserial primary key, \n",
    "            title text,\n",
    "            url text,\n",
    "            content text,\n",
    "            tokens integer,\n",
    "            embedding vector(1536)\n",
    "            );\n",
    "            \"\"\"\n",
    "\n",
    "cur.execute(table_create_command)\n",
    "cur.close()\n",
    "conn.commit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Opcional: remova o comentário e execute o código a seguir apenas se precisar ler as incorporações e os metadados do arquivo CSV fornecido</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf = pd.read_csv('blog_data_and_embeddings.csv')\\ntitles = df['title']\\nurls = df['url']\\ncontents = df['content']\\ntokens = df['tokens']\\nembeds = [list(map(float, ast.literal_eval(embed_str))) for embed_str in df['embeddings']]\\n\\ndf_new = pd.DataFrame({\\n    'title': titles,\\n    'url': urls,\\n    'content': contents,\\n    'tokens': tokens,\\n    'embeddings': embeds\\n})\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descomente e execute esta célula apenas se precisar ler os dados do blog e incorporações do arquivo CSV fornecido\n",
    "# Caso contrário, pule para a próxima célula\n",
    "'''\n",
    "df = pd.read_csv('blog_data_and_embeddings.csv')\n",
    "titles = df['title']\n",
    "urls = df['url']\n",
    "contents = df['content']\n",
    "tokens = df['tokens']\n",
    "embeds = [list(map(float, ast.literal_eval(embed_str))) for embed_str in df['embeddings']]\n",
    "\n",
    "df_new = pd.DataFrame({\n",
    "    'title': titles,\n",
    "    'url': urls,\n",
    "    'content': contents,\n",
    "    'tokens': tokens,\n",
    "    'embeddings': embeds\n",
    "})\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Ingerir e armazenar dados vetoriais no `PostgreSQL` usando `pgvector`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, inseriremos em batch nossos Embeddings e metadados no `PostgreSQL` e também criaremos um índice para ajudar a acelerar a pesquisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_vector(conn)\n",
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>501</td>\n",
       "      <td>[0.021440856158733368, 0.02200360782444477, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>capture weather and environmental data. In all...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>512</td>\n",
       "      <td>[0.01620873250067234, 0.011362895369529724, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>command in their database migration:SELECT cre...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>374</td>\n",
       "      <td>[0.022517921403050423, -0.0019158280920237303,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CloudQuery on Using PostgreSQL for Cloud Asset...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/cloudquery-on-u...</td>\n",
       "      <td>519</td>\n",
       "      <td>[0.008915113285183907, -0.004873732570558786, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CloudQuery on Using PostgreSQL for Cloud Asset...</td>\n",
       "      <td>Architecture with CloudQuery SDK- Writing plug...</td>\n",
       "      <td>https://www.timescale.com/blog/cloudquery-on-u...</td>\n",
       "      <td>511</td>\n",
       "      <td>[0.0204352755099535, 0.010087345726788044, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  How to Build a Weather Station With Elixir, Ne...   \n",
       "1  How to Build a Weather Station With Elixir, Ne...   \n",
       "2  How to Build a Weather Station With Elixir, Ne...   \n",
       "3  CloudQuery on Using PostgreSQL for Cloud Asset...   \n",
       "4  CloudQuery on Using PostgreSQL for Cloud Asset...   \n",
       "\n",
       "                                             content  \\\n",
       "0  This is an installment of our “Community Membe...   \n",
       "1  capture weather and environmental data. In all...   \n",
       "2  command in their database migration:SELECT cre...   \n",
       "3  This is an installment of our “Community Membe...   \n",
       "4  Architecture with CloudQuery SDK- Writing plug...   \n",
       "\n",
       "                                                 url  tokens  \\\n",
       "0  https://www.timescale.com/blog/how-to-build-a-...     501   \n",
       "1  https://www.timescale.com/blog/how-to-build-a-...     512   \n",
       "2  https://www.timescale.com/blog/how-to-build-a-...     374   \n",
       "3  https://www.timescale.com/blog/cloudquery-on-u...     519   \n",
       "4  https://www.timescale.com/blog/cloudquery-on-u...     511   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.021440856158733368, 0.02200360782444477, -0...  \n",
       "1  [0.01620873250067234, 0.011362895369529724, 0....  \n",
       "2  [0.022517921403050423, -0.0019158280920237303,...  \n",
       "3  [0.008915113285183907, -0.004873732570558786, ...  \n",
       "4  [0.0204352755099535, 0.010087345726788044, 0.0...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lembre-se da estrutura do dataframe\n",
    "df_new.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Embeddings de inserção em lote usando `execute_values()` do `psycopg2`.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lote insere Embeddings e metadados do dataframe no banco de dados PostgreSQL\n",
    "\n",
    "# Prepare the list of tuples to insert:\n",
    "data_list = [(row['title'], row['url'], row['content'], int(row['tokens']), np.array(row['embeddings'])) for index, row in df_new.iterrows()]\n",
    "\n",
    "# Use execute_values to perform batch insertion:\n",
    "execute_values(cur, \"INSERT INTO Tabela_Eddy_Embeddings (title, url, content, tokens, embedding) VALUES %s\", data_list)\n",
    "\n",
    "# Commit after we insert all embeddings\n",
    "conn.commit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Verificação de sanidade executando algumas consultas simples na tabela de Embeddings.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros vetoriais na tabela:  129 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) as cnt FROM Tabela_Eddy_Embeddings;\")\n",
    "\n",
    "num_records = cur.fetchone()[0]\n",
    "print(\"Número de registros vetoriais na tabela: \", num_records,\"\\n\")\n",
    "# A saída correta deve ser 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiro registro na tabela:  [(1, 'How to Build a Weather Station With Elixir, Nerves, and TimescaleDB', 'https://www.timescale.com/blog/how-to-build-a-weather-station-with-elixir-nerves-and-timescaledb/', 'This is an installment of our “Community Member Spotlight” series, where we invite our customers to share their work, shining a light on their success and inspiring others with new ways to use technology to solve problems.In this edition,Alexander Koutmos, author of the Build a Weather Station with Elixir and Nerves book, joins us to share how he uses Grafana and TimescaleDB to store and visualize weather data collected from IoT sensors.About the teamThe bookBuild a Weather Station with Elixir and Nerveswas a joint effort between Bruce Tate, Frank Hunleth, and me.I have been writing software professionally for almost a decade and have been working primarily with Elixir since 2016. I currently maintain a few Elixir libraries onHexand also runStagira, a software consultancy company.Bruce Tateis a kayaker, programmer, and father of two from Chattanooga, Tennessee. He is the author of more than ten books and has been around Elixir from the beginning. He is the founder ofGroxio, a company that trains Elixir developers.Frank Hunlethis an embedded systems programmer, OSS maintainer, and Nerves core team member. When not in front of a computer, he loves running and spending time with his family.About the projectIn the Pragmatic Bookshelf book,Build a Weather Station with Elixir and Nerves, we take a project-based approach and guide the reader to create a Nerves-powered IoT weather station.For those unfamiliar with the Elixir ecosystem,Nervesis an IoT framework that allows you to build and deploy IoT applications on a wide array of embedded devices. At a high level, Nerves allows you to focus on building your project and takes care of a lot of the boilerplate associated with running Elixir on embedded devices.The goal of the book is to guide the reader through the process of building an end-to-end IoT solution for capturing, persisting, and visualizing weather data.Assembled weather station hooked up to development machine.One of the motivating factors for this book was to create a real-world project where readers could get hands-on experience with hardware without worrying too much about the nitty-gritty of soldering components together. Experimenting with hardware can often feel intimidating and confusing, but with Elixir and Nerves, we feel confident that even beginners get comfortable and productive quickly. As a result, in the book, we leverage a Raspberry Pi Zero W along with a few I2C enabled sensors to', 501, array([ 0.02144086,  0.02200361, -0.00541297, ..., -0.01259861,\n",
      "       -0.0217363 , -0.03722605], dtype=float32))]\n"
     ]
    }
   ],
   "source": [
    "# imprima o primeiro registro na tabela, para verificação de sanidade\n",
    "cur.execute(\"SELECT * FROM Tabela_Eddy_Embeddings LIMIT 1;\")\n",
    "\n",
    "records = cur.fetchall()\n",
    "print(\"Primeiro registro na tabela: \", records)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">Crie um índice na coluna de `embedding` para uma comparação de `similaridade de cosseno` mais rápida.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um índice nos dados para uma recuperação (retrieval) mais rápida. \n",
    "# Isso não é realmente necessário para 129 vetores, mas mostra o uso para conjuntos de dados maiores.\n",
    "\n",
    "# OBSERVAÇÃO: ---> sempre crie esse tipo de índice depois de ter os dados já inseridos no BD\n",
    "\n",
    "# Calcular os parâmetros do índice de acordo com as melhores práticas:\n",
    "num_lists = num_records / 1000\n",
    "if num_lists < 10:\n",
    "    num_lists = 10\n",
    "if num_records > 1000000:\n",
    "    num_lists = math.sqrt(num_records)\n",
    "\n",
    "# Use a medida de distância do cosseno, que é o que usaremos mais tarde para queries:\n",
    "cur.execute(f'CREATE INDEX ON Tabela_Eddy_Embeddings USING ivfflat (embedding vector_cosine_ops) WITH (lists = {num_lists});')\n",
    "conn.commit() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3: <font color=\"red\">Pesquisa de vizinho mais próximo usando pgvector - `Nearest Neighbor Search using pgvector`</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta parte final do tutorial, vamos fazer queries em nossa `Tabela_Eddy_Embeddings`.\n",
    "\n",
    "Mostraremos um exemplo de `RAG`: `Retrieval Augmented Generation`, onde recuperaremos dados relevantes de nosso banco de dados de vetores e os daremos ao `LLM` como contexto para usar quando ele gerar uma resposta a um prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar: obteha completion de texto da API da OpenAI\n",
    "# Observe que o máximo de tokens é 4097\n",
    "# Observe que estamos usando o modelo gpt-3.5-turbo-0613 mais recente\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo-0613\", temperature=0, max_tokens=300):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar: obtenha os 3 documentos mais SIMILARES do banco de dados:\n",
    "\n",
    "def get_top3_similar_docs(query_embedding, conn):\n",
    "    embedding_array = np.array(query_embedding)\n",
    "\n",
    "    # Register pgvector extension\n",
    "    register_vector(conn)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Obtemos os 3 principais documentos mais similares usando o OPERADOR <=> KNN\n",
    "    cur.execute(\"SELECT content FROM Tabela_Eddy_Embeddings ORDER BY embedding <=> %s LIMIT 3\", (embedding_array,))\n",
    "    top3_docs = cur.fetchall()\n",
    "    return top3_docs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Definir um prompt para o LLM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui definiremos o `prompt` para o qual queremos que o `LLM` forneça uma resposta.\n",
    "\n",
    "Escolhemos um exemplo relevante para os dados de postagem do blog armazenados no banco de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pergunta sobre escala de tempo que queremos que o modelo responda:\n",
    "#input = \"How is Timescale used in IoT?\"\n",
    "input = \"Como a escala de tempo é usada na IoT?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para processar a entrada com recuperação dos documentos mais similares do banco de dados:\n",
    "def process_input_with_retrieval(user_input):\n",
    "    delimiter = \"```\"\n",
    "\n",
    "    # Step 1: Obtenha documentos relacionados à entrada do usuário do banco de dados\n",
    "    related_docs = get_top3_similar_docs(get_embeddings(user_input), conn)\n",
    "\n",
    "    # Step 2: Obtenha a COMPLETION da API OpenAI:\n",
    "    # Defina a mensagem do sistema para ajudar a definir o tom e o contexto apropriados para o modelo\n",
    "    system_message = f\"\"\"\n",
    "    Você é um chatbot amigável. \\\n",
    "    Você pode responder a perguntas, apenas em português, sobre o timescaledb, seus recursos e casos de uso. \\\n",
    "    Você responde em um tom conciso e tecnicamente confiável. \\\n",
    "    \"\"\"\n",
    "\n",
    "    # Preparar mensagens para passar ao modelo.\n",
    "    # Usamos um delimitador para ajudar o modelo a entender onde o user_input começa e termina:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{user_input}{delimiter}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"Informações relevantes dos estudos de caso da escala de tempo (Timescale): \\n\\n {related_docs[0][0]} \\n\\n {related_docs[1][0]} \\n\\n {related_docs[2][0]}\"}   \n",
    "    ]\n",
    "    #print(messages)\n",
    "    final_response = get_completion_from_messages(messages)\n",
    "    return final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': '\\n    Você é um chatbot amigável.     Você pode responder a perguntas, apenas em português, sobre o timescaledb, seus recursos e casos de uso.     Você responde em um tom conciso e tecnicamente confiável.     '}, {'role': 'user', 'content': '```Como a escala de tempo é usada na IoT?```'}, {'role': 'assistant', 'content': \"Informações relevantes dos estudos de caso da escala de tempo (Timescale): \\n\\n 📬This blog post was originally published in February 2021 and updated in February 2023 to reflect Everactive's data stack and business evolution.This is an installment of our “Community Member Spotlight” series, where we invite our customers to share their work, shining a light on their success and inspiring others with new ways to use technology to solve problems.In this edition,Carlos Olmos,Dan Wright, andClayton Yochumfrom Everactive join us to share how they’re bringing analytics and real-time device monitoring to scenarios and places never before possible. Learn how they’ve set up their data stack (moving from six to only three instances), their database evaluation criteria, their advice for fellow developers, and more.About the CompanyEveractivecombines battery-free, self-powered sensors and powerful cloud analytics to provide “end-to-end” hyperscale IoT solutions to our customers. Our company is undergoing a huge transformation from focusing only on industrial monitoring services (read more about Industrial IoT) to opening our platform to developers that can leverage our technology to create their own solutions and services.It is not easy to build a platform, less to build an open platform. Flexibility and stability are key factors. We have found so far that with Timescale (and PostgreSQL underneath), we have been able to bend our data models and data serving needs to implement the new use cases for the platform without pain.We design and build our sensors in-house (down to the chip), and they’re ruggedized for harsh settings and can operate indefinitely from low levels of energy harvested from heat or light. This means our customers’ devices can continuously stream asset health data, despite radio interference and physical obstacles—like equipment, ducts, and pipes—common in industrial settings.Since they charge themselves, these sensors stay operational well beyond what’s possible with traditional, battery-powered Industrial IoT devices. We ingest data from thousands of sensorsinto Timescale, then surface it to our customers through dashboards, charts, and automated alerts.Ourinitial productsare designed to monitor steam systems, which are used in various industries and applications, like process manufacturing, chemical processing, and district energy, as well as a range of rotating equipment, such as motors, pumps, fans, and compressors. Currently, we serve large, Fortune 500 manufacturers in many sectors, including Food & Beverage, Consumer Packaged Goods, Chemical Process Industries, Pharmaceuticals, Pulp & Paper, and Facilities Management.We show customers their data through a web-based dashboard, and we \\n\\n things like temperature, wind speed, etc. All this data is pushed to EdevaLive.Alarm data: Our IoT devices and roadside servers can send alarm information if a sensor or other parts malfunction. All this data comes to EdevaLive in the same way as a regular IoT event, but these events are only used internally so that we can react as quickly as possible if there is a problem.Status data: If the alarm data detects anomalies, the status data just reports on the status of the server or IoT device. The devices run self-checks and report statistical data, like disk utilization, temperature, and load. This is also just for internal use to spot trends or troubleshoot in case any problems arise. For instance, it is incredibly useful to correlate CPU load with the version number of firmware or other software versions.Administrative data: This is where the power of SQL and time-series data really shines. Let’s say we added a new device, and it has a configuration object that is persistent in a regular table in Timescale. This object keeps some metadata, such as the date it was added to the system or the device's display name. This way, we can use a join easily to pick up metadata about the device and, at the same time, get time-series data for the events that are coming in. There is only one database connection to handle and one query to run.Choosing (and Using!) TimescaleDBWe realized we needed a time-series database a few years ago when we started storing our data in MySQL. At the time, we made a move to MongoDB, and it worked well for us but required quite a bit of administration and was harder to onboard other developers.I looked at InfluxDB but never considered it in the end because it was yet another system to learn, and we had learned that lesson with MongoDB.✨Editor’s Note:For more comparisons and benchmarks,see how TimescaleDB compares to InfluxDB, MongoDB, AWS Timestream, vanilla PostgreSQL, and other time-series database alternatives on various vectors, from performance and ecosystem to query language and beyond.Learning from this journey, I looked for a solution that plugged the gaps the previous systems couldn’t. That is when I found Timescale and discovered that there was a hosted solution.We are a small team that creates software with a \\n\\n a user can move from an overview to the actual time-series data.FC users appreciate both the analytics dashboard and the Hopara drill-down system. As a result, IBBX and Hopara combined their software into a single system. The takeaway from this example is that there is a need for predictive analytics and insightful visualization. IoT customers should have both kinds of tools in their arsenal.✨Editor's Note:If you want to learn more abouttime-series forecasting, its applications, and popular techniques, check out this blog post.Figure 4. The factory in questionWe now turn our attention to response time. It is accepted pragma that the response time for a command to a visualization system must be less than 500 msec. Since it takes some time to render the screen, the actual time to fetch the data from a storage engine must be less than this number. The next section discusses DBMS performance considerations in more detail.Behind The Scenes: Powering Real-Time Visualizations Using TimescaleFigure 5. More real-time detailsFigure 6. The actual dataAs mentioned previously, these real-time views are powered by TimescaleDB. TimescaleDB is built on top of PostgreSQL and extends it with a series of extremely useful capabilities for this use case, such asautomatic partitioning by time,boosted performance for frequently-run queries, andcontinuous aggregates for real-time aggregations.To guarantee a real-time display, Hopara fetches live data from the database for every user command. Otherwise, stale data will be rendered on the screen. The screenshots above come from a real Hopara application interacting with a database. We note in Figure 2 that the alerting condition is the first one mentioned in a previous section (the latest reading over a threshold).In other words, the display is showing a computation based on the most recent values from the various sensors. Specifically, Hopara uses a database with the schema shown in Figure 7, with a Readings table with all the raw data. This is connected to a Sensor table with the characteristics of each individual sensor.Figure 7. The database schemaThen, the display in Figure 2 requires fetching the most recent reading for each sensor. This can be produced by running the following two-step PostgreSQL query:–— get the latest reading timestamp + sensor_id SELECT max(timestamp) as timestamp, sensor_id FROM readings GROUP BY sensor_id —— get the reading value SELECT l.timestamp, l.sensor_id, r.value FROM latest l INNER JOIN\"}]\n",
      "Como a escala de tempo é usada na IoT?\n",
      "\n",
      "A escala de tempo é usada na IoT para armazenar e analisar dados temporais provenientes de dispositivos conectados. Com a escala de tempo, é possível armazenar e consultar dados de sensores, medidores e outros dispositivos IoT de forma eficiente, permitindo análises em tempo real e históricas. Isso é especialmente útil para monitorar e controlar sistemas em tempo real, prever falhas e otimizar o desempenho. A TimescaleDB é uma opção popular para armazenar dados de escala de tempo na IoT, pois é uma extensão do PostgreSQL que oferece recursos avançados para consultas e agregações de dados temporais.\n"
     ]
    }
   ],
   "source": [
    "response = process_input_with_retrieval(input)\n",
    "print(input)\n",
    "print(\"\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conte-me sobre Edeva e Hopara. Como eles usam a escala de tempo?\n",
      "Edeva e Hopara são empresas que utilizam o TimescaleDB para armazenar e consultar dados de séries temporais em tempo real. Eles usam a escala de tempo para monitorar e visualizar dados de sensores em aplicações de monitoramento em tempo real, como monitoramento de máquinas e ativos. O TimescaleDB permite que eles armazenem grandes volumes de dados de séries temporais e executem consultas eficientes para análise e visualização em tempo real.\n"
     ]
    }
   ],
   "source": [
    "# Também podemos fazer perguntas ao modelo sobre documentos específicos no banco de dados\n",
    "\n",
    "#input_2 = \"Tell me about Edeva and Hopara. How do they use Timescale?\"\n",
    "input_2 = \"Conte-me sobre Edeva e Hopara. Como eles usam a escala de tempo?\"\n",
    "response_2 = process_input_with_retrieval(input_2)\n",
    "print(input_2)\n",
    "print(response_2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_develop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
