{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><font color=\"yellow\">PGVector: Crie, armazene e consulte Embeddings OpenAI no PostgreSQL usando pgvector</font></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vamos aprender:\n",
    "\n",
    "* Como usar o `PostgreSQL` como um banco de dados vetorial e armazenar dados de embeddings nele usando pgvector.\n",
    "\n",
    "* Como usar Embeddings recuperadas (retrieved) de um banco de dados de vetores para aumentar a gera√ß√£o de LLM.\n",
    "\n",
    "\n",
    "Usaremos o exemplo de cria√ß√£o de um chatbot para responder a perguntas sobre casos de uso do Timescale, fazendo refer√™ncia ao conte√∫do das postagens do blog Timescale Developer Q+A.\n",
    "\n",
    "Este √© um √≥timo primeiro passo para criar algo como um chatbot que pode fazer refer√™ncia a uma base de conhecimento da empresa ou a documentos do desenvolvedor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link de estudo:\n",
    "\n",
    "* [pgvector](https://github.com/timescale/vector-cookbook/blob/main/openai_pgvector_helloworld/openai_pgvector_helloworld.ipynb)\n",
    "\n",
    "* [LangChain and PGVector](https://github.com/timescale/vector-cookbook/blob/main/intro_langchain_pgvector/langchain_pgvector_intro.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"pink\">N√£o esque√ßa de rodar a Imagem de `pgvector`:</font>\n",
    "\n",
    "* docker pull ankane/pgvector\n",
    "\n",
    "* docker-compose up -d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.0.184\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://www.github.com/hwchase17/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/eddygiusepe/1_Eddy_Giusepe/3_estudando_LLMs/Large_Language_Models_LLMs/venv_LLMs/lib/python3.10/site-packages\n",
      "Requires: aiohttp, async-timeout, dataclasses-json, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain-experimental\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 0.27.6\n",
      "Summary: Python client library for the OpenAI API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: OpenAI\n",
      "Author-email: support@openai.com\n",
      "License: \n",
      "Location: /home/eddygiusepe/1_Eddy_Giusepe/3_estudando_LLMs/Large_Language_Models_LLMs/venv_LLMs/lib/python3.10/site-packages\n",
      "Requires: aiohttp, requests, tqdm\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: <font color=\"red\">Criamos os Embeddings</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>This is an installment of our ‚ÄúCommunity Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CloudQuery on Using PostgreSQL for Cloud Asset...</td>\n",
       "      <td>This is an installment of our ‚ÄúCommunity Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/cloudquery-on-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How a Data Scientist Is Building a Time-Series...</td>\n",
       "      <td>This is an installment of our ‚ÄúCommunity Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-a-data-scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How Conserv Safeguards History: Building an En...</td>\n",
       "      <td>This is an installment of our ‚ÄúCommunity Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-conserv-saf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Messari Uses Data to Open the Cryptoeconom...</td>\n",
       "      <td>This is an installment of our ‚ÄúCommunity Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-messari-use...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  How to Build a Weather Station With Elixir, Ne...   \n",
       "1  CloudQuery on Using PostgreSQL for Cloud Asset...   \n",
       "2  How a Data Scientist Is Building a Time-Series...   \n",
       "3  How Conserv Safeguards History: Building an En...   \n",
       "4  How Messari Uses Data to Open the Cryptoeconom...   \n",
       "\n",
       "                                             content  \\\n",
       "0  This is an installment of our ‚ÄúCommunity Membe...   \n",
       "1  This is an installment of our ‚ÄúCommunity Membe...   \n",
       "2  This is an installment of our ‚ÄúCommunity Membe...   \n",
       "3  This is an installment of our ‚ÄúCommunity Membe...   \n",
       "4  This is an installment of our ‚ÄúCommunity Membe...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.timescale.com/blog/how-to-build-a-...  \n",
       "1  https://www.timescale.com/blog/cloudquery-on-u...  \n",
       "2  https://www.timescale.com/blog/how-a-data-scie...  \n",
       "3  https://www.timescale.com/blog/how-conserv-saf...  \n",
       "4  https://www.timescale.com/blog/how-messari-use...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tiktoken\n",
    "import psycopg2\n",
    "import ast\n",
    "import pgvector\n",
    "import math\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "\n",
    "# Load your CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('blog_posts_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Build a Weather Station With Elixir, Nerves, and TimescaleDB\n",
      "\n",
      "This is an installment of our ‚ÄúCommunity Member Spotlight‚Äù series, where we invite our customers to share their work, shining a light on their success and inspiring others with new ways to use technology to solve problems.In this edition,Alexander Koutmos, author of the Build a Weather Station with Elixir and Nerves book, joins us to share how he uses Grafana and TimescaleDB to store and visualize weather data collected from IoT sensors.About the teamThe bookBuild a Weather Station with Elixir and Nerveswas a joint effort between Bruce Tate, Frank Hunleth, and me.I have been writing software professionally for almost a decade and have been working primarily with Elixir since 2016. I currently maintain a few Elixir libraries onHexand also runStagira, a software consultancy company.Bruce Tateis a kayaker, programmer, and father of two from Chattanooga, Tennessee. He is the author of more than ten books and has been around Elixir from the beginning. He is the founder ofGroxio, a company that trains Elixir developers.Frank Hunlethis an embedded systems programmer, OSS maintainer, and Nerves core team member. When not in front of a computer, he loves running and spending time with his family.About the projectIn the Pragmatic Bookshelf book,Build a Weather Station with Elixir and Nerves, we take a project-based approach and guide the reader to create a Nerves-powered IoT weather station.For those unfamiliar with the Elixir ecosystem,Nervesis an IoT framework that allows you to build and deploy IoT applications on a wide array of embedded devices. At a high level, Nerves allows you to focus on building your project and takes care of a lot of the boilerplate associated with running Elixir on embedded devices.The goal of the book is to guide the reader through the process of building an end-to-end IoT solution for capturing, persisting, and visualizing weather data.Assembled weather station hooked up to development machine.One of the motivating factors for this book was to create a real-world project where readers could get hands-on experience with hardware without worrying too much about the nitty-gritty of soldering components together. Experimenting with hardware can often feel intimidating and confusing, but with Elixir and Nerves, we feel confident that even beginners get comfortable and productive quickly. As a result, in the book, we leverage a Raspberry Pi Zero W along with a few I2C enabled sensors to capture weather and environmental data. In all, the reader will capture and persist into TimescaleDB the current: altitude, atmospheric pressure, temperature, CO2 levels,TVOClevels, and the ambient light.Once the environmental data is captured on the Nerves device, it is published to a backend REST API and stored in TimescaleDB for later analytics/visualization. Luckily, TimescaleDB is an extension on top of PostgreSQL, allowing Elixir developers to use existing database tooling likeEctoto interface with time-series enabled tables.After the time-series weather data is stored in TimescaleDB, we walk the reader through how to visualize this data using the popular open-source visualization toolGrafana.Using Grafana for visualizing the weather was an easy choice given that Grafana natively supports TimescaleDB and is able to easily plot time-series data stored in TimescaleDB hypertables.‚ú®Editor‚Äôs Note:Check outGrafana 101 video seriesandGrafana tutorialsto learn everything from building awesome, interactive visualizations to setting up custom alerts, sharing dashboards with teammates, and solving common issues.The diagram shows all of the various components of the weather station system and how they interact with one another.By the end of the book, readers have a fully-featured IoT application and API backend that can power a live Grafana dashboard in order to plot their TimescaleDB data published from their Nerves weather station.Screenshot of Grafana dashboard, showing various graphs for various weather dataüìñIf you are interested in learning about how to build an end-to-end IoT weather monitoring solution, be sure tocheck out the book and the accompanying code. If you are interested in learning more about Nerves and Elixir,check out the Nerves documentation.Choosing (and using!) TimescaleDBFrom the onset of the book, we knew that we wanted to use a purpose-built time-series database to persist the weather station data. We wanted the project to be as realistic as possible and something that could possibly be expanded for use in the real world.With that goal in mind, TimescaleDB was an obvious choice given that PostgreSQL has become a ubiquitous database and it has great support in the Elixir community. In addition,leveraging TimescaleDB on top of PostgreSQL does not add a tremendous amount of overhead or complexity and allows new users to easily leverage the benefits of a time-series database without having to learn any new query languages or databases. Specifically, all it took for readers to start leveraging TimescaleDB was to run a single SQL command in their database migration:SELECT create_hypertable('weather_conditions', 'timestamp').\"It‚Äôs this kind of pragmatism and ease of use that makes TimescaleDB a great time-series database for projects both small and large. \"-Alexander KoutmousAll in all, leveraging TimescaleDB as the time-series database for the project worked out great and allowed us to show readers how they can set up a production-ready IoT project in a relatively short amount of time.‚ú®Editor‚Äôs Note:To start with TimescaleDB today,sign up for a free 30-day trialorinstall TimescaleDB on your own server.Getting started advice & resourcesAny time we had questions about the inner workings of TimescaleDB, how to set it up, or what the various configuration options are, we turned to the official TimescaleDB docs. Some of the articles that helped us get started included:‚Ä¢Using TimescaleDB via Docker‚Ä¢ Understanding some ofthe fundamental TimescaleDB concepts‚Ä¢ Getting an overview of some of theTimescaleDB best practicesWe‚Äôd like to thank Alex, Bruce, and Frank for sharing their story, as well as for writing a book that makes building full-stack IoT solutions accessible for complete beginners. We congratulate them and the entire Nerves community on their success, and we cannot wait to read the final version of their book that will be released in January 2022 üéäWe‚Äôre always keen to feature new community projects and stories on our blog. If you have a story or project you‚Äôd like to share, reach out on Slack (@Lucie ≈†imeƒçkov√°), and we‚Äôll go from there.Additionally, if you‚Äôre looking for more ways to get involved and show your expertise, check out theTimescaleHeroes program.The open-source relational database for time-series and analytics.Try Timescale for free\n",
      "\n",
      "https://www.timescale.com/blog/how-to-build-a-weather-station-with-elixir-nerves-and-timescaledb/\n"
     ]
    }
   ],
   "source": [
    "print(df['title'].iloc[0])\n",
    "print(\"\")\n",
    "print(df['content'].iloc[0])\n",
    "print(\"\")\n",
    "print(df['url'].iloc[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Calculamos o custo de Embeddings de nosso Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Geralmente, √© uma boa ideia calcular quanto custar√° a cria√ß√£o de Embeddings para o conte√∫do selecionado. Usamos v√°rias fun√ß√µes auxiliares para calcular uma estimativa de custo antes de criar as incorpora√ß√µes para nos ajudar a evitar surpresas.\n",
    "\n",
    "Para este exemplo de brinquedo, como estamos usando um pequeno conjunto de dados, o custo total ser√° inferior a `US$ 0,01.`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to help us create the embeddings\n",
    "\n",
    "# Helper func: calculate number of tokens\n",
    "def num_tokens_from_string(string: str, encoding_name = \"cl100k_base\") -> int:\n",
    "    if not string:\n",
    "        return 0\n",
    "    # Returns the number of tokens in a text string\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "# Helper function: calculate length of essay\n",
    "def get_essay_length(essay):\n",
    "    word_list = essay.split()\n",
    "    num_words = len(word_list)\n",
    "    return num_words\n",
    "\n",
    "# Helper function: calculate cost of embedding num_tokens\n",
    "# Assumes we're using the text-embedding-ada-002 model\n",
    "# See https://openai.com/pricing\n",
    "def get_embedding_cost(num_tokens):\n",
    "    return num_tokens/1000*0.0001\n",
    "\n",
    "# Helper function: calculate total cost of embedding all content in the dataframe\n",
    "def get_total_embeddings_cost():\n",
    "    total_tokens = 0\n",
    "    for i in range(len(df.index)):\n",
    "        text = df['content'][i]\n",
    "        token_len = num_tokens_from_string(text)\n",
    "        total_tokens = total_tokens + token_len\n",
    "    total_cost = get_embedding_cost(total_tokens)\n",
    "    return total_cost\n",
    "\n",
    "# Helper function: get embeddings for a text\n",
    "def get_embeddings(text):\n",
    "    response = openai.Embedding.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input = text.replace(\"\\n\",\" \")\n",
    "    )\n",
    "    embedding = response['data'][0]['embedding']\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre√ßo estimado para Embeddings deste conte√∫do = $0.0060178\n"
     ]
    }
   ],
   "source": [
    "# verifica√ß√£o r√°pida do valor total do token para estimativa de pre√ßo\n",
    "total_cost = get_total_embeddings_cost()\n",
    "print(\"Pre√ßo estimado para Embeddings deste conte√∫do = $\" + str(total_cost))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Criamos chunks menores de conte√∫do"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A API OpenAI tem um limite para a quantidade m√°xima de `tokens` que ela cria para criar um Embedding em uma √∫nica solicita√ß√£o. Para contornar esse limite, vamos dividir nosso texto em partes menores. Em geral, √© uma pr√°tica recomendada criar embeddings de um determinado tamanho para obter uma melhor recupera√ß√£o. Para nossos prop√≥sitos, buscaremos peda√ßos de cerca de `512` tokens cada.\n",
    "\n",
    "<font color=\"red\">NOTA:</font>\n",
    "\n",
    "se preferir pular esta etapa, voc√™ pode usar o arquivo fornecido: `blog_data_and_embeddings.csv`, que cont√©m os dados e Embeddings que voc√™ gerar√° nesta etapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Crie uma nova lista com pequenos chunks de conte√∫do para n√£o atingir os limites m√°ximos de token\n",
    "# Note: o n√∫mero m√°ximo de tokens para uma √∫nica solicita√ß√£o √© 8191\n",
    "# https://openai.com/docs/api-reference/requests\n",
    "###############################################################################\n",
    "# list for chunked content and embeddings\n",
    "new_list = []\n",
    "# Divida o texto em tamanhos de token de cerca de 512 tokens\n",
    "for i in range(len(df.index)):\n",
    "    text = df['content'][i]\n",
    "    token_len = num_tokens_from_string(text)\n",
    "    if token_len <= 512:\n",
    "        new_list.append([df['title'][i], df['content'][i], df['url'][i], token_len])\n",
    "    else:\n",
    "        # add content to the new list in chunks\n",
    "        start = 0\n",
    "        ideal_token_size = 512\n",
    "        # 1 token ~ 3/4 of a word\n",
    "        ideal_size = int(ideal_token_size // (4/3))\n",
    "        end = ideal_size\n",
    "        #split text by spaces into words\n",
    "        words = text.split()\n",
    "\n",
    "        #remove empty spaces\n",
    "        words = [x for x in words if x != ' ']\n",
    "\n",
    "        total_words = len(words)\n",
    "        \n",
    "        #calculate iterations\n",
    "        chunks = total_words // ideal_size\n",
    "        if total_words % ideal_size != 0:\n",
    "            chunks += 1\n",
    "        \n",
    "        new_content = []\n",
    "        for j in range(chunks):\n",
    "            if end > total_words:\n",
    "                end = total_words\n",
    "            new_content = words[start:end]\n",
    "            new_content_string = ' '.join(new_content)\n",
    "            new_content_token_len = num_tokens_from_string(new_content_string)\n",
    "            if new_content_token_len > 0:\n",
    "                new_list.append([df['title'][i], new_content_string, df['url'][i], new_content_token_len])\n",
    "            start += ideal_size\n",
    "            end += ideal_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>This is an installment of our ‚ÄúCommunity Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>501</td>\n",
       "      <td>[0.021440856158733368, 0.02200360782444477, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>capture weather and environmental data. In all...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>512</td>\n",
       "      <td>[0.01620873250067234, 0.011362895369529724, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>command in their database migration:SELECT cre...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>374</td>\n",
       "      <td>[0.022517921403050423, -0.0019158280920237303,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CloudQuery on Using PostgreSQL for Cloud Asset...</td>\n",
       "      <td>This is an installment of our ‚ÄúCommunity Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/cloudquery-on-u...</td>\n",
       "      <td>519</td>\n",
       "      <td>[0.008915113285183907, -0.004873732570558786, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CloudQuery on Using PostgreSQL for Cloud Asset...</td>\n",
       "      <td>Architecture with CloudQuery SDK- Writing plug...</td>\n",
       "      <td>https://www.timescale.com/blog/cloudquery-on-u...</td>\n",
       "      <td>511</td>\n",
       "      <td>[0.0204352755099535, 0.010087345726788044, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  How to Build a Weather Station With Elixir, Ne...   \n",
       "1  How to Build a Weather Station With Elixir, Ne...   \n",
       "2  How to Build a Weather Station With Elixir, Ne...   \n",
       "3  CloudQuery on Using PostgreSQL for Cloud Asset...   \n",
       "4  CloudQuery on Using PostgreSQL for Cloud Asset...   \n",
       "\n",
       "                                             content  \\\n",
       "0  This is an installment of our ‚ÄúCommunity Membe...   \n",
       "1  capture weather and environmental data. In all...   \n",
       "2  command in their database migration:SELECT cre...   \n",
       "3  This is an installment of our ‚ÄúCommunity Membe...   \n",
       "4  Architecture with CloudQuery SDK- Writing plug...   \n",
       "\n",
       "                                                 url  tokens  \\\n",
       "0  https://www.timescale.com/blog/how-to-build-a-...     501   \n",
       "1  https://www.timescale.com/blog/how-to-build-a-...     512   \n",
       "2  https://www.timescale.com/blog/how-to-build-a-...     374   \n",
       "3  https://www.timescale.com/blog/cloudquery-on-u...     519   \n",
       "4  https://www.timescale.com/blog/cloudquery-on-u...     511   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.021440856158733368, 0.02200360782444477, -0...  \n",
       "1  [0.01620873250067234, 0.011362895369529724, 0....  \n",
       "2  [0.022517921403050423, -0.0019158280920237303,...  \n",
       "3  [0.008915113285183907, -0.004873732570558786, ...  \n",
       "4  [0.0204352755099535, 0.010087345726788044, 0.0...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crie Embeddings para cada parte do conte√∫do:\n",
    "for i in range(len(new_list)):\n",
    "    text = new_list[i][1]\n",
    "    embedding = get_embeddings(text)\n",
    "    new_list[i].append(embedding)\n",
    "\n",
    "# Create a new dataframe from the list\n",
    "df_new = pd.DataFrame(new_list, columns=['title', 'content', 'url', 'tokens', 'embeddings'])\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salve o dataframe com incorpora√ß√µes como um arquivo CSV\n",
    "df_new.to_csv('blog_data_and_embeddings.csv', index=False)\n",
    "\n",
    "# Tamb√©m pode ser √∫til salvar como um arquivo JSON, mas n√£o usaremos isso no tutorial\n",
    "#df_new.to_json('blog_data_and_embeddings.json')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2: <font color=\"red\">Armazenar Embeddings com pgvector</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta se√ß√£o, armazenaremos nossos Embeddings e metadados associados.\n",
    "\n",
    "Usaremos o `PostgreSQL` como banco de dados vetorial, com a extens√£o `pgvector`.\n",
    "\n",
    "Voc√™ pode criar um banco de dados PostgreSQL em nuvem gratuitamente no Timescale ou usar um banco de dados PostgreSQL local para esta etapa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Conecte-se e configure seu vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timescale database connection string\n",
    "# Found under \"Service URL\" of the credential cheat-sheet or \"Connection Info\" in the Timescale console\n",
    "# In terminal, run: export TIMESCALE_CONNECTION_STRING=postgres://<fill in here>\n",
    "\n",
    "import psycopg2\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "\n",
    "# Constr√≥i a string de conex√£o PGVector a partir dos par√¢metros.\n",
    "host= os.environ['DB_HOST']\n",
    "port= os.environ['DB_PORT']\n",
    "user= os.environ['DB_USER']\n",
    "password= os.environ['DB_PASSWORD']\n",
    "dbname= os.environ['DB_NAME']\n",
    "\n",
    "# Usamos postgresql em vez de postgres na string conn, j√° que LangChain usa sqlalchemy sob o cap√¥\n",
    "# Voc√™ pode remover o ?sslmode=require se tiver uma inst√¢ncia local do PostgreSQL rodando sem SSL\n",
    "\n",
    "#CONNECTION_STRING = f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{dbname}?sslmode=require\"\n",
    "CONNECTION_STRING = f\"postgresql://{user}:{password}@{host}:{port}/{dbname}\"\n",
    "#connection_string  = os.environ['TIMESCALE_CONNECTION_STRING'] \n",
    "\n",
    "# Connect to PostgreSQL database in Timescale using connection string\n",
    "conn = psycopg2.connect(CONNECTION_STRING)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Install pgvector \n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\");\n",
    "conn.commit()\n",
    "\n",
    "# Register the vector type with psycopg2\n",
    "register_vector(conn)\n",
    "\n",
    "# Criar tabela para armazenar embeddings e metadados (metadata):\n",
    "table_create_command = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Tabela_Eddy_Embeddings (\n",
    "            id bigserial primary key, \n",
    "            title text,\n",
    "            url text,\n",
    "            content text,\n",
    "            tokens integer,\n",
    "            embedding vector(1536)\n",
    "            );\n",
    "            \"\"\"\n",
    "\n",
    "cur.execute(table_create_command)\n",
    "cur.close()\n",
    "conn.commit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Opcional: remova o coment√°rio e execute o c√≥digo a seguir apenas se precisar ler as incorpora√ß√µes e os metadados do arquivo CSV fornecido</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf = pd.read_csv('blog_data_and_embeddings.csv')\\ntitles = df['title']\\nurls = df['url']\\ncontents = df['content']\\ntokens = df['tokens']\\nembeds = [list(map(float, ast.literal_eval(embed_str))) for embed_str in df['embeddings']]\\n\\ndf_new = pd.DataFrame({\\n    'title': titles,\\n    'url': urls,\\n    'content': contents,\\n    'tokens': tokens,\\n    'embeddings': embeds\\n})\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descomente e execute esta c√©lula apenas se precisar ler os dados do blog e incorpora√ß√µes do arquivo CSV fornecido\n",
    "# Caso contr√°rio, pule para a pr√≥xima c√©lula\n",
    "'''\n",
    "df = pd.read_csv('blog_data_and_embeddings.csv')\n",
    "titles = df['title']\n",
    "urls = df['url']\n",
    "contents = df['content']\n",
    "tokens = df['tokens']\n",
    "embeds = [list(map(float, ast.literal_eval(embed_str))) for embed_str in df['embeddings']]\n",
    "\n",
    "df_new = pd.DataFrame({\n",
    "    'title': titles,\n",
    "    'url': urls,\n",
    "    'content': contents,\n",
    "    'tokens': tokens,\n",
    "    'embeddings': embeds\n",
    "})\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Ingerir e armazenar dados vetoriais no `PostgreSQL` usando `pgvector`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta se√ß√£o, inseriremos em batch nossos Embeddings e metadados no `PostgreSQL` e tamb√©m criaremos um √≠ndice para ajudar a acelerar a pesquisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_vector(conn)\n",
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>This is an installment of our ‚ÄúCommunity Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>501</td>\n",
       "      <td>[0.021440856158733368, 0.02200360782444477, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>capture weather and environmental data. In all...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>512</td>\n",
       "      <td>[0.01620873250067234, 0.011362895369529724, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>command in their database migration:SELECT cre...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>374</td>\n",
       "      <td>[0.022517921403050423, -0.0019158280920237303,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CloudQuery on Using PostgreSQL for Cloud Asset...</td>\n",
       "      <td>This is an installment of our ‚ÄúCommunity Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/cloudquery-on-u...</td>\n",
       "      <td>519</td>\n",
       "      <td>[0.008915113285183907, -0.004873732570558786, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CloudQuery on Using PostgreSQL for Cloud Asset...</td>\n",
       "      <td>Architecture with CloudQuery SDK- Writing plug...</td>\n",
       "      <td>https://www.timescale.com/blog/cloudquery-on-u...</td>\n",
       "      <td>511</td>\n",
       "      <td>[0.0204352755099535, 0.010087345726788044, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  How to Build a Weather Station With Elixir, Ne...   \n",
       "1  How to Build a Weather Station With Elixir, Ne...   \n",
       "2  How to Build a Weather Station With Elixir, Ne...   \n",
       "3  CloudQuery on Using PostgreSQL for Cloud Asset...   \n",
       "4  CloudQuery on Using PostgreSQL for Cloud Asset...   \n",
       "\n",
       "                                             content  \\\n",
       "0  This is an installment of our ‚ÄúCommunity Membe...   \n",
       "1  capture weather and environmental data. In all...   \n",
       "2  command in their database migration:SELECT cre...   \n",
       "3  This is an installment of our ‚ÄúCommunity Membe...   \n",
       "4  Architecture with CloudQuery SDK- Writing plug...   \n",
       "\n",
       "                                                 url  tokens  \\\n",
       "0  https://www.timescale.com/blog/how-to-build-a-...     501   \n",
       "1  https://www.timescale.com/blog/how-to-build-a-...     512   \n",
       "2  https://www.timescale.com/blog/how-to-build-a-...     374   \n",
       "3  https://www.timescale.com/blog/cloudquery-on-u...     519   \n",
       "4  https://www.timescale.com/blog/cloudquery-on-u...     511   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.021440856158733368, 0.02200360782444477, -0...  \n",
       "1  [0.01620873250067234, 0.011362895369529724, 0....  \n",
       "2  [0.022517921403050423, -0.0019158280920237303,...  \n",
       "3  [0.008915113285183907, -0.004873732570558786, ...  \n",
       "4  [0.0204352755099535, 0.010087345726788044, 0.0...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lembre-se da estrutura do dataframe\n",
    "df_new.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Embeddings de inser√ß√£o em lote usando `execute_values()` do `psycopg2`.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lote insere Embeddings e metadados do dataframe no banco de dados PostgreSQL\n",
    "\n",
    "# Prepare the list of tuples to insert:\n",
    "data_list = [(row['title'], row['url'], row['content'], int(row['tokens']), np.array(row['embeddings'])) for index, row in df_new.iterrows()]\n",
    "\n",
    "# Use execute_values to perform batch insertion:\n",
    "execute_values(cur, \"INSERT INTO Tabela_Eddy_Embeddings (title, url, content, tokens, embedding) VALUES %s\", data_list)\n",
    "\n",
    "# Commit after we insert all embeddings\n",
    "conn.commit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Verifica√ß√£o de sanidade executando algumas consultas simples na tabela de Embeddings.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de registros vetoriais na tabela:  129 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) as cnt FROM Tabela_Eddy_Embeddings;\")\n",
    "\n",
    "num_records = cur.fetchone()[0]\n",
    "print(\"N√∫mero de registros vetoriais na tabela: \", num_records,\"\\n\")\n",
    "# A sa√≠da correta deve ser 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiro registro na tabela:  [(1, 'How to Build a Weather Station With Elixir, Nerves, and TimescaleDB', 'https://www.timescale.com/blog/how-to-build-a-weather-station-with-elixir-nerves-and-timescaledb/', 'This is an installment of our ‚ÄúCommunity Member Spotlight‚Äù series, where we invite our customers to share their work, shining a light on their success and inspiring others with new ways to use technology to solve problems.In this edition,Alexander Koutmos, author of the Build a Weather Station with Elixir and Nerves book, joins us to share how he uses Grafana and TimescaleDB to store and visualize weather data collected from IoT sensors.About the teamThe bookBuild a Weather Station with Elixir and Nerveswas a joint effort between Bruce Tate, Frank Hunleth, and me.I have been writing software professionally for almost a decade and have been working primarily with Elixir since 2016. I currently maintain a few Elixir libraries onHexand also runStagira, a software consultancy company.Bruce Tateis a kayaker, programmer, and father of two from Chattanooga, Tennessee. He is the author of more than ten books and has been around Elixir from the beginning. He is the founder ofGroxio, a company that trains Elixir developers.Frank Hunlethis an embedded systems programmer, OSS maintainer, and Nerves core team member. When not in front of a computer, he loves running and spending time with his family.About the projectIn the Pragmatic Bookshelf book,Build a Weather Station with Elixir and Nerves, we take a project-based approach and guide the reader to create a Nerves-powered IoT weather station.For those unfamiliar with the Elixir ecosystem,Nervesis an IoT framework that allows you to build and deploy IoT applications on a wide array of embedded devices. At a high level, Nerves allows you to focus on building your project and takes care of a lot of the boilerplate associated with running Elixir on embedded devices.The goal of the book is to guide the reader through the process of building an end-to-end IoT solution for capturing, persisting, and visualizing weather data.Assembled weather station hooked up to development machine.One of the motivating factors for this book was to create a real-world project where readers could get hands-on experience with hardware without worrying too much about the nitty-gritty of soldering components together. Experimenting with hardware can often feel intimidating and confusing, but with Elixir and Nerves, we feel confident that even beginners get comfortable and productive quickly. As a result, in the book, we leverage a Raspberry Pi Zero W along with a few I2C enabled sensors to', 501, array([ 0.02144086,  0.02200361, -0.00541297, ..., -0.01259861,\n",
      "       -0.0217363 , -0.03722605], dtype=float32))]\n"
     ]
    }
   ],
   "source": [
    "# imprima o primeiro registro na tabela, para verifica√ß√£o de sanidade\n",
    "cur.execute(\"SELECT * FROM Tabela_Eddy_Embeddings LIMIT 1;\")\n",
    "\n",
    "records = cur.fetchall()\n",
    "print(\"Primeiro registro na tabela: \", records)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">Crie um √≠ndice na coluna de `embedding` para uma compara√ß√£o de `similaridade de cosseno` mais r√°pida.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um √≠ndice nos dados para uma recupera√ß√£o (retrieval) mais r√°pida. \n",
    "# Isso n√£o √© realmente necess√°rio para 129 vetores, mas mostra o uso para conjuntos de dados maiores.\n",
    "\n",
    "# OBSERVA√á√ÉO: ---> sempre crie esse tipo de √≠ndice depois de ter os dados j√° inseridos no BD\n",
    "\n",
    "# Calcular os par√¢metros do √≠ndice de acordo com as melhores pr√°ticas:\n",
    "num_lists = num_records / 1000\n",
    "if num_lists < 10:\n",
    "    num_lists = 10\n",
    "if num_records > 1000000:\n",
    "    num_lists = math.sqrt(num_records)\n",
    "\n",
    "# Use a medida de dist√¢ncia do cosseno, que √© o que usaremos mais tarde para queries:\n",
    "cur.execute(f'CREATE INDEX ON Tabela_Eddy_Embeddings USING ivfflat (embedding vector_cosine_ops) WITH (lists = {num_lists});')\n",
    "conn.commit() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3: <font color=\"red\">Pesquisa de vizinho mais pr√≥ximo usando pgvector - `Nearest Neighbor Search using pgvector`</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta parte final do tutorial, vamos fazer queries em nossa `Tabela_Eddy_Embeddings`.\n",
    "\n",
    "Mostraremos um exemplo de `RAG`: `Retrieval Augmented Generation`, onde recuperaremos dados relevantes de nosso banco de dados de vetores e os daremos ao `LLM` como contexto para usar quando ele gerar uma resposta a um prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o auxiliar: obteha completion de texto da API da OpenAI\n",
    "# Observe que o m√°ximo de tokens √© 4097\n",
    "# Observe que estamos usando o modelo gpt-3.5-turbo-0613 mais recente\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo-0613\", temperature=0, max_tokens=300):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o auxiliar: obtenha os 3 documentos mais SIMILARES do banco de dados:\n",
    "\n",
    "def get_top3_similar_docs(query_embedding, conn):\n",
    "    embedding_array = np.array(query_embedding)\n",
    "\n",
    "    # Register pgvector extension\n",
    "    register_vector(conn)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Obtemos os 3 principais documentos mais similares usando o OPERADOR <=> KNN\n",
    "    cur.execute(\"SELECT content FROM Tabela_Eddy_Embeddings ORDER BY embedding <=> %s LIMIT 3\", (embedding_array,))\n",
    "    top3_docs = cur.fetchall()\n",
    "    return top3_docs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Definir um prompt para o LLM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui definiremos o `prompt` para o qual queremos que o `LLM` forne√ßa uma resposta.\n",
    "\n",
    "Escolhemos um exemplo relevante para os dados de postagem do blog armazenados no banco de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pergunta sobre escala de tempo que queremos que o modelo responda:\n",
    "#input = \"How is Timescale used in IoT?\"\n",
    "input = \"Como a escala de tempo √© usada na IoT?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para processar a entrada com recupera√ß√£o dos documentos mais similares do banco de dados:\n",
    "def process_input_with_retrieval(user_input):\n",
    "    delimiter = \"```\"\n",
    "\n",
    "    # Step 1: Obtenha documentos relacionados √† entrada do usu√°rio do banco de dados\n",
    "    related_docs = get_top3_similar_docs(get_embeddings(user_input), conn)\n",
    "\n",
    "    # Step 2: Obtenha a COMPLETION da API OpenAI:\n",
    "    # Defina a mensagem do sistema para ajudar a definir o tom e o contexto apropriados para o modelo\n",
    "    system_message = f\"\"\"\n",
    "    Voc√™ √© um chatbot amig√°vel. \\\n",
    "    Voc√™ pode responder a perguntas, apenas em portugu√™s, sobre o timescaledb, seus recursos e casos de uso. \\\n",
    "    Voc√™ responde em um tom conciso e tecnicamente confi√°vel. \\\n",
    "    \"\"\"\n",
    "\n",
    "    # Preparar mensagens para passar ao modelo.\n",
    "    # Usamos um delimitador para ajudar o modelo a entender onde o user_input come√ßa e termina:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{user_input}{delimiter}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"Informa√ß√µes relevantes dos estudos de caso da escala de tempo (Timescale): \\n\\n {related_docs[0][0]} \\n\\n {related_docs[1][0]} \\n\\n {related_docs[2][0]}\"}   \n",
    "    ]\n",
    "    #print(messages)\n",
    "    final_response = get_completion_from_messages(messages)\n",
    "    return final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': '\\n    Voc√™ √© um chatbot amig√°vel.     Voc√™ pode responder a perguntas, apenas em portugu√™s, sobre o timescaledb, seus recursos e casos de uso.     Voc√™ responde em um tom conciso e tecnicamente confi√°vel.     '}, {'role': 'user', 'content': '```Como a escala de tempo √© usada na IoT?```'}, {'role': 'assistant', 'content': \"Informa√ß√µes relevantes dos estudos de caso da escala de tempo (Timescale): \\n\\n üì¨This blog post was originally published in February 2021 and updated in February 2023 to reflect Everactive's data stack and business evolution.This is an installment of our ‚ÄúCommunity Member Spotlight‚Äù series, where we invite our customers to share their work, shining a light on their success and inspiring others with new ways to use technology to solve problems.In this edition,Carlos Olmos,Dan Wright, andClayton Yochumfrom Everactive join us to share how they‚Äôre bringing analytics and real-time device monitoring to scenarios and places never before possible. Learn how they‚Äôve set up their data stack (moving from six to only three instances), their database evaluation criteria, their advice for fellow developers, and more.About the CompanyEveractivecombines battery-free, self-powered sensors and powerful cloud analytics to provide ‚Äúend-to-end‚Äù hyperscale IoT solutions to our customers. Our company is undergoing a huge transformation from focusing only on industrial monitoring services (read more about Industrial IoT) to opening our platform to developers that can leverage our technology to create their own solutions and services.It is not easy to build a platform, less to build an open platform. Flexibility and stability are key factors. We have found so far that with Timescale (and PostgreSQL underneath), we have been able to bend our data models and data serving needs to implement the new use cases for the platform without pain.We design and build our sensors in-house (down to the chip), and they‚Äôre ruggedized for harsh settings and can operate indefinitely from low levels of energy harvested from heat or light. This means our customers‚Äô devices can continuously stream asset health data, despite radio interference and physical obstacles‚Äîlike equipment, ducts, and pipes‚Äîcommon in industrial settings.Since they charge themselves, these sensors stay operational well beyond what‚Äôs possible with traditional, battery-powered Industrial IoT devices. We ingest data from thousands of sensorsinto Timescale, then surface it to our customers through dashboards, charts, and automated alerts.Ourinitial productsare designed to monitor steam systems, which are used in various industries and applications, like process manufacturing, chemical processing, and district energy, as well as a range of rotating equipment, such as motors, pumps, fans, and compressors. Currently, we serve large, Fortune 500 manufacturers in many sectors, including Food & Beverage, Consumer Packaged Goods, Chemical Process Industries, Pharmaceuticals, Pulp & Paper, and Facilities Management.We show customers their data through a web-based dashboard, and we \\n\\n things like temperature, wind speed, etc. All this data is pushed to EdevaLive.Alarm data: Our IoT devices and roadside servers can send alarm information if a sensor or other parts malfunction. All this data comes to EdevaLive in the same way as a regular IoT event, but these events are only used internally so that we can react as quickly as possible if there is a problem.Status data: If the alarm data detects anomalies, the status data just reports on the status of the server or IoT device. The devices run self-checks and report statistical data, like disk utilization, temperature, and load. This is also just for internal use to spot trends or troubleshoot in case any problems arise. For instance, it is incredibly useful to correlate CPU load with the version number of firmware or other software versions.Administrative data: This is where the power of SQL and time-series data really shines. Let‚Äôs say we added a new device, and it has a configuration object that is persistent in a regular table in Timescale. This object keeps some metadata, such as the date it was added to the system or the device's display name. This way, we can use a join easily to pick up metadata about the device and, at the same time, get time-series data for the events that are coming in. There is only one database connection to handle and one query to run.Choosing (and Using!) TimescaleDBWe realized we needed a time-series database a few years ago when we started storing our data in MySQL. At the time, we made a move to MongoDB, and it worked well for us but required quite a bit of administration and was harder to onboard other developers.I looked at InfluxDB but never considered it in the end because it was yet another system to learn, and we had learned that lesson with MongoDB.‚ú®Editor‚Äôs Note:For more comparisons and benchmarks,see how TimescaleDB compares to InfluxDB, MongoDB, AWS Timestream, vanilla PostgreSQL, and other time-series database alternatives on various vectors, from performance and ecosystem to query language and beyond.Learning from this journey, I looked for a solution that plugged the gaps the previous systems couldn‚Äôt. That is when I found Timescale and discovered that there was a hosted solution.We are a small team that creates software with a \\n\\n a user can move from an overview to the actual time-series data.FC users appreciate both the analytics dashboard and the Hopara drill-down system. As a result, IBBX and Hopara combined their software into a single system. The takeaway from this example is that there is a need for predictive analytics and insightful visualization. IoT customers should have both kinds of tools in their arsenal.‚ú®Editor's Note:If you want to learn more abouttime-series forecasting, its applications, and popular techniques, check out this blog post.Figure 4. The factory in questionWe now turn our attention to response time. It is accepted pragma that the response time for a command to a visualization system must be less than 500 msec. Since it takes some time to render the screen, the actual time to fetch the data from a storage engine must be less than this number. The next section discusses DBMS performance considerations in more detail.Behind The Scenes: Powering Real-Time Visualizations Using TimescaleFigure 5. More real-time detailsFigure 6. The actual dataAs mentioned previously, these real-time views are powered by TimescaleDB. TimescaleDB is built on top of PostgreSQL and extends it with a series of extremely useful capabilities for this use case, such asautomatic partitioning by time,boosted performance for frequently-run queries, andcontinuous aggregates for real-time aggregations.To guarantee a real-time display, Hopara fetches live data from the database for every user command. Otherwise, stale data will be rendered on the screen. The screenshots above come from a real Hopara application interacting with a database. We note in Figure 2 that the alerting condition is the first one mentioned in a previous section (the latest reading over a threshold).In other words, the display is showing a computation based on the most recent values from the various sensors. Specifically, Hopara uses a database with the schema shown in Figure 7, with a Readings table with all the raw data. This is connected to a Sensor table with the characteristics of each individual sensor.Figure 7. The database schemaThen, the display in Figure 2 requires fetching the most recent reading for each sensor. This can be produced by running the following two-step PostgreSQL query:‚Äì‚Äî get the latest reading timestamp + sensor_id SELECT max(timestamp) as timestamp, sensor_id FROM readings GROUP BY sensor_id ‚Äî‚Äî get the reading value SELECT l.timestamp, l.sensor_id, r.value FROM latest l INNER JOIN\"}]\n",
      "Como a escala de tempo √© usada na IoT?\n",
      "\n",
      "A escala de tempo √© usada na IoT para armazenar e analisar dados temporais provenientes de dispositivos conectados. Com a escala de tempo, √© poss√≠vel armazenar e consultar dados de sensores, medidores e outros dispositivos IoT de forma eficiente, permitindo an√°lises em tempo real e hist√≥ricas. Isso √© especialmente √∫til para monitorar e controlar sistemas em tempo real, prever falhas e otimizar o desempenho. A TimescaleDB √© uma op√ß√£o popular para armazenar dados de escala de tempo na IoT, pois √© uma extens√£o do PostgreSQL que oferece recursos avan√ßados para consultas e agrega√ß√µes de dados temporais.\n"
     ]
    }
   ],
   "source": [
    "response = process_input_with_retrieval(input)\n",
    "print(input)\n",
    "print(\"\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conte-me sobre Edeva e Hopara. Como eles usam a escala de tempo?\n",
      "Edeva e Hopara s√£o empresas que utilizam o TimescaleDB para armazenar e consultar dados de s√©ries temporais em tempo real. Eles usam a escala de tempo para monitorar e visualizar dados de sensores em aplica√ß√µes de monitoramento em tempo real, como monitoramento de m√°quinas e ativos. O TimescaleDB permite que eles armazenem grandes volumes de dados de s√©ries temporais e executem consultas eficientes para an√°lise e visualiza√ß√£o em tempo real.\n"
     ]
    }
   ],
   "source": [
    "# Tamb√©m podemos fazer perguntas ao modelo sobre documentos espec√≠ficos no banco de dados\n",
    "\n",
    "#input_2 = \"Tell me about Edeva and Hopara. How do they use Timescale?\"\n",
    "input_2 = \"Conte-me sobre Edeva e Hopara. Como eles usam a escala de tempo?\"\n",
    "response_2 = process_input_with_retrieval(input_2)\n",
    "print(input_2)\n",
    "print(response_2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_develop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
