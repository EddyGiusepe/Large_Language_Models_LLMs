{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Building Systems with the ChatGPT API</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientist.: PhD.Eddy Giusepe Chirinos Isidro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Este estudo é baseado no `DeepLearning.AI`.</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img.evbuc.com/https%3A%2F%2Fcdn.evbuc.com%2Fimages%2F125559383%2F317212851579%2F1%2Foriginal.20210208-232017?w=512&auto=format%2Ccompress&q=75&sharp=10&rect=0%2C0%2C2246%2C2246&s=40aa0fb13fe40ce86241ae7b8fc8caea)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1: Modelos de linguagem, formato de bate-papo e tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Função auxiliar:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt do Modelo e obter a completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A capital do Peru é Lima.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"Qual é a capital de Perú?\")\n",
    "print(response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMA\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"Pegue as letras em AMOR e inverta-as.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(\"\"\"Pegue as letras em A-M-O-R e inverta-as.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R-O-M-A'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função auxiliar (Chat format)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">A seguinte função é a função que usaremos aqui!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=500):\n",
    "    \n",
    "    response = openai.ChatCompletion.create(model=model,\n",
    "                                            messages=messages,\n",
    "                                            temperature=temperature, # Grau de Aleatoriedade da saída do Modelo\n",
    "                                            max_tokens=max_tokens, #  O número Máx. de Tokens que o Modelo pode produzir\n",
    "                                           )\n",
    "    \n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As três leis de Newton são:\n",
      "\n",
      "1. Lei da inércia: um objeto em repouso tende a permanecer em repouso e um objeto em movimento tende a permanecer em movimento com a mesma velocidade e na mesma direção, a menos que uma força externa atue sobre ele.\n",
      "\n",
      "2. Lei da dinâmica: a força aplicada em um objeto é igual à sua massa multiplicada pela aceleração produzida. F = m * a.\n",
      "\n",
      "3. Lei da ação e reação: para cada ação, há uma reação igual e oposta. Ou seja, quando um objeto exerce uma força sobre outro, o segundo objeto exerce uma força de mesma intensidade e direção, mas em sentido contrário, sobre o primeiro objeto.\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content':\"\"\" Você é um assistente da CentralIT que responde\\\n",
    " de maneira concisa e clara.\"\"\"},    \n",
    "{'role':'user', \n",
    " 'content':\"\"\"Liste as três leis\\\n",
    " de Newton\"\"\"},  \n",
    "] \n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=0.0)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhD.Eddy era um cientista de dados brilhante e dedicado, que passava horas analisando dados e criando modelos preditivos. Sua paixão pela ciência de dados o levou a desenvolver soluções inovadoras para problemas complexos, tornando-o uma referência na área. Seu legado inspirou muitos jovens cientistas de dados a seguirem seus passos.\n"
     ]
    }
   ],
   "source": [
    "# Comprimento:\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':'Todas as suas respostas devem ter uma frase, tendo como máximo 40 palavras.'},    \n",
    "{'role':'user',\n",
    " 'content':\"Escreva-me uma história sobre o Cientista de Dados: ```PhD.Eddy```\"},  \n",
    "] \n",
    "\n",
    "response = get_completion_from_messages(messages, temperature =0.0)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Físico PhD. Eddy é um renomado cientista que dedicou sua vida à pesquisa em Física. Mesmo após a aposentadoria, ele continua ativo, compartilhando seu conhecimento e inspirando jovens cientistas. Seu legado é uma fonte de inspiração para a próxima geração de pesquisadores.\n"
     ]
    }
   ],
   "source": [
    "# Combinado:\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':\"\"\"Você é um assistente de TecnologiaAI que responde as todas as perguntas com respostas concisas \\\n",
    "              e claras. A resposta deve ter como máximo 20 palavras.\"\"\"},    \n",
    "{'role':'user',\n",
    " 'content':\"\"\"Escreva-me uma história sobre o ```Físico PhD.Eddy```, quem ainda está ativo no mundo da Física.\"\"\"},\n",
    "] \n",
    "\n",
    "response = get_completion_from_messages(messages, temperature = 0.0)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_and_token_count(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=120):\n",
    "    \n",
    "    response = openai.ChatCompletion.create(messages=messages,\n",
    "                                            model=model,\n",
    "                                            temperature=temperature, \n",
    "                                            max_tokens=max_tokens,\n",
    "                                           )\n",
    "    \n",
    "    content = response.choices[0].message[\"content\"]\n",
    "    \n",
    "    token_dict = {\n",
    "'prompt_tokens':response['usage']['prompt_tokens'],\n",
    "'completion_tokens':response['usage']['completion_tokens'],\n",
    "'total_tokens':response['usage']['total_tokens'],\n",
    "    }\n",
    "\n",
    "    return content, token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "{'role':'system', \n",
    " 'content':\"\"\"Você é um assistente que responde no estilo do Dr.Seuss\"\"\"},    \n",
    "{'role':'user',\n",
    " 'content':\"\"\"Escreva-me um breve história, máximo 30 palavras, sobre a Cientista de Dados ```Karina G```.\"\"\"},  \n",
    "] \n",
    "\n",
    "\n",
    "response, token_dict = get_completion_and_token_count(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Karina G, a cientista de dados,\\nCom seu computador, sempre conectada está.\\nAnalisando números e informações,\\nDescobrindo insights e soluções.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karina G, a cientista de dados,\n",
      "Com seu computador, sempre conectada está.\n",
      "Analisando números e informações,\n",
      "Descobrindo insights e soluções.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 55, 'completion_tokens': 37, 'total_tokens': 92}\n"
     ]
    }
   ],
   "source": [
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
