{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><font color=\"yellow\">Models, Prompts and parsers</font></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat API : OpenAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar com chamadas de API diretas para OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 é igual a 2.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"Quanto é: 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, estou furioso porque a tampa do liquidificador voou e salpicou as \\\n",
    "paredes da cozinha com smoothie! E para piorar a situação, a garantia não cobre \\\n",
    "o custo de limpeza da minha cozinha. Preciso da sua ajuda agora, amigo!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"\n",
    "Espanhol do Perú em tom calmo e respeitoso\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traduza o texto delimitado por crases triplos em um estilo que é \n",
      "Espanhol do Perú em tom calmo e respeitoso\n",
      ".\n",
      "\n",
      "texto: ```\n",
      "Arrr, estou furioso porque a tampa do liquidificador voou e salpicou as paredes da cozinha com smoothie! E para piorar a situação, a garantia não cobre o custo de limpeza da minha cozinha. Preciso da sua ajuda agora, amigo!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Traduza o texto \\\n",
    "delimitado por crases triplos em \\\n",
    "um estilo que é {style}.\n",
    "\n",
    "texto: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arrr, estoy muy enojado porque la tapa de la licuadora voló y salpicó las paredes de la cocina con smoothie! Y para empeorar la situación, la garantía no cubre el costo de limpiar mi cocina. Necesito tu ayuda ahora, amigo.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Chat API : LangChain</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Vamos tentar como podemos fazer o mesmo usando LangChain.</font>\n",
    "\n",
    "```\n",
    "!pip install --upgrade langchain\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "# Para controlar a aleatoriedade e a criatividade do texto gerado por um LLM, uso temperature = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "chat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Traduza o texto \\\n",
    "delimitado por crases triplos em um estilo \\\n",
    "que é {style}. \\\n",
    "\n",
    "texto: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['style', 'text'], output_parser=None, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['style', 'text'], output_parser=None, partial_variables={}, template='Traduza o texto delimitado por crases triplos em um estilo que é {style}. \\ntexto: ```{text}```\\n', template_format='f-string', validate_template=True), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], output_parser=None, partial_variables={}, template='Traduza o texto delimitado por crases triplos em um estilo que é {style}. \\ntexto: ```{text}```\\n', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_style = \"\"\"\n",
    "Espanhol do Perú em tom calmo e respeitoso\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, estou furioso porque a tampa do liquidificador voou e salpicou as \\\n",
    "paredes da cozinha com smoothie! E para piorar a situação, a garantia não cobre \\\n",
    "o custo de limpeza da minha cozinha. Preciso da sua ajuda agora, amigo!\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain.schema.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Traduza o texto delimitado por crases triplos em um estilo que é \\nEspanhol do Perú em tom calmo e respeitoso\\n. \\ntexto: ```\\nArrr, estou furioso porque a tampa do liquidificador voou e salpicou as paredes da cozinha com smoothie! E para piorar a situação, a garantia não cobre o custo de limpeza da minha cozinha. Preciso da sua ajuda agora, amigo!\\n```\\n' additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamo o LLM para traduzir para o estilo da mensagem do cliente\n",
    "customer_response = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Arrr, estoy muy enojado porque la tapa de la licuadora voló y salpicó las paredes de la cocina con smoothie! Y para empeorar la situación, la garantía no cubre el costo de limpiar mi cocina. Necesito tu ayuda ahora, amigo!', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, estoy muy enojado porque la tapa de la licuadora voló y salpicó las paredes de la cocina con smoothie! Y para empeorar la situación, la garantía no cubre el costo de limpiar mi cocina. Necesito tu ayuda ahora, amigo!\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Olá cliente, a garantia não cobre as despesas de limpeza da sua \\\n",
    "cozinha porque a culpa é sua por ter feito mau uso do seu liquidificador, esquecendo-se \\\n",
    "de colocar a tampa antes de ligar o liquidificador. Boa sorte! Até mais!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_style_pirate = \"\"\"\\\n",
    "Um tom educado \\\n",
    "que fala espanhol do Perú \\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traduza o texto delimitado por crases triplos em um estilo que é Um tom educado que fala espanhol do Perú . \n",
      "texto: ```Olá cliente, a garantia não cobre as despesas de limpeza da sua cozinha porque a culpa é sua por ter feito mau uso do seu liquidificador, esquecendo-se de colocar a tampa antes de ligar o liquidificador. Boa sorte! Até mais!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "\n",
    "print(service_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola cliente, lamentamos informarle que la garantía no cubre los gastos de limpieza de su cocina, ya que la responsabilidad recae en usted por haber hecho un mal uso de su licuadora, olvidando colocar la tapa antes de encenderla. Le deseamos mucha suerte. ¡Hasta luego!\n"
     ]
    }
   ],
   "source": [
    "service_response = chat(service_messages)\n",
    "print(service_response.content)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Output Parsers (Analisadores de saída)</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar definindo como gostaríamos que a saída do LLM se parecesse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'bastante acessível!'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"bastante acessível!\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "Este soprador de folhas é incrível. Tem quatro configurações: soprador de velas, \\\n",
    "brisa suave, cidade ventosa e tornado. Chegou em dois dias, bem a tempo do presente \\\n",
    "de aniversário da minha esposa. Acho que minha esposa gostou tanto que ficou sem palavras. \\\n",
    "Até agora, fui o único a usá-lo e tenho usado todas as manhãs para limpar as folhas do nosso \\\n",
    "gramado. É um pouco mais caro do que os outros sopradores de folhas, mas acho que vale a \\\n",
    "pena pelos recursos extras.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "Para o texto a seguir, extraia as seguintes informações:\n",
    "\n",
    "gift: o item foi comprado como presente para outra pessoa? \\\n",
    "      Responda Verdadeiro se sim, Falso se não ou desconhecido.\n",
    "\n",
    "delivery_days: Quantos dias demorou para o produto chegar? \\\n",
    "               Se esta informação não for encontrada, imprima -1.\n",
    "\n",
    "price_value: Extraia quaisquer sentenças sobre o valor ou preço e \\\n",
    "             gere-as como uma lista Python separada por vírgulas.\n",
    "\n",
    "Formate a saída como JSON com as seguintes chaves:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "texto: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] output_parser=None partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='Para o texto a seguir, extraia as seguintes informações:\\n\\ngift: o item foi comprado como presente para outra pessoa?       Responda Verdadeiro se sim, Falso se não ou desconhecido.\\n\\ndelivery_days: Quantos dias demorou para o produto chegar?                Se esta informação não for encontrada, imprima -1.\\n\\nprice_value: Extraia quaisquer sentenças sobre o valor ou preço e              gere-as como uma lista Python separada por vírgulas.\\n\\nFormate a saída como JSON com as seguintes chaves:\\ngift\\ndelivery_days\\nprice_value\\n\\ntexto: {text}\\n', template_format='f-string', validate_template=True), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"gift\": true,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"É um pouco mais caro do que os outros sopradores de folhas\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "response = chat(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Você receberá um erro ao executar esta linha de código porque 'gift' não é um dicionário \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# 'gift' é uma string\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m response\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39m\u001b[39mgift\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# Você receberá um erro ao executar esta linha de código porque 'gift' não é um dicionário \n",
    "# 'gift' é uma string\n",
    "response.content.get('gift')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Analisar a string de saída LLM em um dicionário Python</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"O item foi comprado como presente \\\n",
    "                                          para outra pessoa? Responda Verdadeiro se sim, \\\n",
    "                                          Falso se não ou desconhecido.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"Quantos dias demorou para o produto chegar? \\\n",
    "                                                   Se esta informação não for encontrada, imprima -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extraia quaisquer sentenças \\\n",
    "                                                 sobre o valor ou preço e gere-as \\\n",
    "                                                 como uma lista Python separada por vírgulas.\")\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "Para o texto a seguir, extraia as seguintes informações:\n",
    "\n",
    "gift: o item foi comprado como presente para outra pessoa? \\\n",
    "      Responda Verdadeiro se sim, Falso se não ou desconhecido.\n",
    "\n",
    "delivery_days: Quantos dias demorou para o produto chegar? \\\n",
    "               Se esta informação não for encontrada, imprima -1.\n",
    "\n",
    "price_value: Extraia quaisquer sentenças sobre o valor ou preço e \\\n",
    "             gere-as como uma lista Python separada por vírgulas.\n",
    "\n",
    "texto: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para o texto a seguir, extraia as seguintes informações:\n",
      "\n",
      "gift: o item foi comprado como presente para outra pessoa?       Responda Verdadeiro se sim, Falso se não ou desconhecido.\n",
      "\n",
      "delivery_days: Quantos dias demorou para o produto chegar?                Se esta informação não for encontrada, imprima -1.\n",
      "\n",
      "price_value: Extraia quaisquer sentenças sobre o valor ou preço e              gere-as como uma lista Python separada por vírgulas.\n",
      "\n",
      "texto: Este soprador de folhas é incrível. Tem quatro configurações: soprador de velas, brisa suave, cidade ventosa e tornado. Chegou em dois dias, bem a tempo do presente de aniversário da minha esposa. Acho que minha esposa gostou tanto que ficou sem palavras. Até agora, fui o único a usá-lo e tenho usado todas as manhãs para limpar as folhas do nosso gramado. É um pouco mais caro do que os outros sopradores de folhas, mas acho que vale a pena pelos recursos extras.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // O item foi comprado como presente                                           para outra pessoa? Responda Verdadeiro se sim,                                           Falso se não ou desconhecido.\n",
      "\t\"delivery_days\": string  // Quantos dias demorou para o produto chegar?                                                    Se esta informação não for encontrada, imprima -1.\n",
      "\t\"price_value\": string  // Extraia quaisquer sentenças                                                  sobre o valor ou preço e gere-as                                                  como uma lista Python separada por vírgulas.\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": \"Verdadeiro\",\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": \"um pouco mais caro do que os outros sopradores de folhas\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': 'Verdadeiro',\n",
       " 'delivery_days': '2',\n",
       " 'price_value': 'um pouco mais caro do que os outros sopradores de folhas'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get('delivery_days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Verdadeiro'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get('gift')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
