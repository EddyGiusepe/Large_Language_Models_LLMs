{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><font color=\"yellow\">LangChain: Agents ü§ñ</font></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links de estudo:\n",
    "\n",
    "* [LangChain Chat with Custom Tools, Functions and Memory](https://medium.com/@gil.fernandes/langchain-chat-with-custom-tools-functions-and-memory-e34daa331aa7)\n",
    "\n",
    "* [How to connect LLM to SQL database with LangChain SQLChain](https://medium.com/dataherald/how-to-langchain-sqlchain-c7342dd41614)\n",
    "\n",
    "* [Chat with SQL database via LangChain SQLDatabaseChain](https://github.com/sugarforever/LangChain-SQL-Chain/tree/main)\n",
    "\n",
    "* [LangChain: pinecone-io](https://github.com/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/06-langchain-agents.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Os agentes s√£o como \"ferramentas\" (`Tools`) para `LLMs`. Eles permitem que um LLM acesse a `Google Search`, execute c√°lculos complexos com `Python` e at√© mesmo fa√ßa consultas `SQL`.\n",
    "\n",
    "Neste Notebook, exploraremos os `agentes` e como us√°-los no `LangChain`.\n",
    "\n",
    "Come√ßaremos instalando as bibliotecas de pr√©-requisito que usaremos neste exemplo.</font>\n",
    "\n",
    "```\n",
    "!pip install -qU langchain openai google-search-results wikipedia sqlalchemy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain openai google-search-results wikipedia sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.0.265\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://www.github.com/hwchase17/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/eddygiusepe/1_Eddy_Giusepe/3_estudando_LLMs/Large_Language_Models_LLMs/venv_LLMs/lib/python3.10/site-packages\n",
      "Requires: aiohttp, async-timeout, dataclasses-json, langsmith, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "\n",
    "\n",
    "Eddy_API_KEY_OpenAI = os.environ['OPENAI_API_KEY'] \n",
    "\n",
    "llm = OpenAI(\n",
    "    openai_api_key=Eddy_API_KEY_OpenAI,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Como fizemos antes, contaremos nossos tokens em cada chamada.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "def count_tokens(agent, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = agent(query)\n",
    "        print(f'Gastou um total de {cb.total_tokens} Tokens')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Com tudo isso configurado, vamos pular para Agentes.</font>\n",
    "\n",
    "\n",
    "<font color=\"red\">O que √© um agente?</font>\n",
    "\n",
    "<font color=\"pink\">Defini√ß√£o:</font> \n",
    "\n",
    "A chave por tr√°s dos `agentes` √© dar aos LLM's a possibilidade de usar ferramentas em seu fluxo de trabalho. √â aqui que o langchain se afasta da popular implementa√ß√£o do `ChatGPT` e podemos come√ßar a ter uma ideia do que ele nos oferece como construtores. At√© agora, cobrimos v√°rios blocos de constru√ß√£o isoladamente. Vamos v√™-los ganhar vida.\n",
    "\n",
    "A defini√ß√£o oficial de agentes √© a seguinte:\n",
    "\n",
    ">> Os agentes usam um LLM para determinar quais a√ß√µes devem ser executadas e em que ordem. Uma a√ß√£o pode ser usar uma ferramenta e observar sua sa√≠da ou retornar ao usu√°rio.\n",
    "\n",
    "Nesta edi√ß√£o, abordaremos o que podemos chamar de agentes \"gen√©ricos\" que realmente s√£o capazes de realizar muitas metatarefas. Existem outros agentes mais espec√≠ficos que s√£o ajustados para tarefas diferentes (chamados `kits de ferramentas de agente`), mas iremos abord√°-los em uma edi√ß√£o futura.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Criar um Database</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Usaremos os agentes para interagir com um pequeno banco de dados de amostras de a√ß√µes. N√£o vamos nos aprofundar nos detalhes porque esta √© apenas uma ferramenta fict√≠cia que construiremos para fins ilustrativos. Vamos cri√°-lo.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData\n",
    "\n",
    "metadata_obj = MetaData()\n",
    "\n",
    "\n",
    "from sqlalchemy import Column, Integer, String, Table, Date, Float\n",
    "\n",
    "stocks = Table(\n",
    "    \"stocks\",\n",
    "    metadata_obj,\n",
    "    Column(\"obs_id\", Integer, primary_key=True),\n",
    "    Column(\"stock_ticker\", String(4), nullable=False),\n",
    "    Column(\"price\", Float, nullable=False),\n",
    "    Column(\"date\", Date, nullable=False),    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite:///database_eddy.db\")\n",
    "metadata_obj.create_all(engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "observations = [\n",
    "    [1, 'ABC', 200, datetime(2023, 1, 1)],\n",
    "    [2, 'ABC', 208, datetime(2023, 1, 2)],\n",
    "    [3, 'ABC', 232, datetime(2023, 1, 3)],\n",
    "    [4, 'ABC', 225, datetime(2023, 1, 4)],\n",
    "    [5, 'ABC', 226, datetime(2023, 1, 5)],\n",
    "    [6, 'XYZ', 810, datetime(2023, 1, 1)],\n",
    "    [7, 'XYZ', 803, datetime(2023, 1, 2)],\n",
    "    [8, 'XYZ', 798, datetime(2023, 1, 3)],\n",
    "    [9, 'XYZ', 795, datetime(2023, 1, 4)],\n",
    "    [10, 'XYZ', 791, datetime(2023, 1, 5)],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "def insert_obs(obs):\n",
    "    stmt = insert(stocks).values(\n",
    "    obs_id=obs[0], \n",
    "    stock_ticker=obs[1], \n",
    "    price=obs[2],\n",
    "    date=obs[3]\n",
    "    )\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(stmt)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obs in observations:\n",
    "    insert_obs(obs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/use_cases/sql\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "\n",
    "db = SQLDatabase(engine)\n",
    "sql_chain = SQLDatabaseChain.from_llm(llm=llm, db=db, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Por fim, criaremos uma ferramenta com essa cadeia (`chain`). Para criar uma ferramenta personalizada, precisamos apenas de tr√™s entradas:\n",
    "\n",
    "* `name:` o nome da ferramenta (enviado para o llm como contexto)\n",
    "\n",
    "* `func:` a fun√ß√£o que ser√° aplicada na requisi√ß√£o do `LLM`\n",
    "\n",
    "* `description:` a descri√ß√£o da ferramenta, para que ela deve ser usada (enviada para o llm como contexto)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "sql_tool = Tool(\n",
    "    name='Stock DB',\n",
    "    func=sql_chain.run,\n",
    "    description=\"√ötil para quando voc√™ precisa responder a perguntas sobre a√ß√µes e seus pre√ßos.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Tipos de Agente</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta se√ß√£o, revisaremos v√°rios agentes e veremos como eles 'pensam' e o que podem fazer.\n",
    "\n",
    "O uso de um dos agentes pr√©-constru√≠dos do `langchain`` envolve tr√™s vari√°veis:\n",
    "\n",
    "* Definindo as ferramentas (`Tools`)\n",
    "\n",
    "* Definindo o llm\n",
    "\n",
    "* Definindo o tipo de agente\n",
    "\n",
    "Isso tudo √© muito f√°cil de fazer no `langchain``, como veremos no exemplo a seguir.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\">1. Tipo de Agente `Zero Shot React`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos apenas algumas ferramentas, mas voc√™ pode combinar as que preferir. Lembre-se de que as ferramentas s√£o apenas correntes (`chains`) de utilidade sob o cap√¥, que s√£o correntes que servem a um prop√≥sito espec√≠fico.\n",
    "\n",
    "Primeiro precisamos inicializar as ferramentas (`tools`) que usaremos neste exemplo. Aqui queremos que nosso agente fa√ßa `matem√°tica`, ent√£o usaremos `'llm-math'`, a ferramenta que temos para resolver problemas matem√°ticos. Esta √© uma das v√°rias ferramentas que podemos carregar com o utilit√°rio `load_tools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    [\"llm-math\"], \n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Para poder pesquisar os pre√ßos de nossas a√ß√µes, tamb√©m usaremos a ferramenta personalizada que constru√≠mos anteriormente com os dados `sql` ('Stock DB'). Acrescentaremos esta Tool √† nossa lista de Tools.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.append(sql_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o nome sugere, usaremos este agente para executar tarefas de `'zero shot'` na entrada. Isso significa que n√£o teremos v√°rias intera√ß√µes interdependentes, mas apenas uma. `Em outras palavras, este agente n√£o ter√° mem√≥ria`.\n",
    "\n",
    "Agora estamos prontos para inicializar o agente! Usaremos `verbose` em `True` para que possamos ver qual √© o processo de 'pensamento' do nosso agente.\n",
    "\n",
    "\n",
    "<font color=\"red\">Observa√ß√£o Importante:</font> \n",
    "\n",
    "Ao interagir com os agentes, √© muito importante definir os par√¢metros `max_iterations` porque os agentes podem ficar presos em loops infinitos que consomem muitos tokens. O valor padr√£o √© `15` para permitir muitas Tools e racioc√≠nio complexo, mas para a maioria dos aplicativos voc√™ deve mant√™-lo bem mais baixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\", \n",
    "    tools=tools, \n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Vamos ver nosso agente rec√©m-criado em a√ß√£o! Faremos uma pergunta que envolve uma opera√ß√£o matem√°tica sobre os pre√ßos das a√ß√µes.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the ratio between the two stocks on 3 January and the ratio between the same stocks on 4 January.\n",
      "Action: Stock DB\n",
      "Action Input: Prices of 'ABC' and 'XYZ' on 3 January and 4 January\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "Prices of 'ABC' and 'XYZ' on 3 January and 4 January\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT stock_ticker, price, date FROM stocks WHERE stock_ticker IN ('ABC', 'XYZ') AND date IN ('2023-01-03', '2023-01-04');\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('ABC', 232.0, '2023-01-03'), ('ABC', 225.0, '2023-01-04'), ('XYZ', 798.0, '2023-01-03'), ('XYZ', 795.0, '2023-01-04')]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mOn 3 January, ABC was 232.0 and XYZ was 798.0. On 4 January, ABC was 225.0 and XYZ was 795.0.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mOn 3 January, ABC was 232.0 and XYZ was 798.0. On 4 January, ABC was 225.0 and XYZ was 795.0.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the ratio between the two stocks on 3 January and the ratio between the same stocks on 4 January.\n",
      "Action: Calculator\n",
      "Action Input: 232.0/798.0 and 225.0/795.0\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 0.08228117463469994\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The multiplication of the ratio between the prices of 'ABC' and 'XYZ' on 3 January and the ratio between the same prices of stocks on 4 January is 0.08228117463469994.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Gastou um total de 2458 Tokens\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    zero_shot_agent, \n",
    "    \"Qual √© a multiplica√ß√£o da rela√ß√£o entre a√ß√µes de \" +\n",
    "    \"pre√ßos de 'ABC' e 'XYZ' em 3 de janeiro e a rela√ß√£o \" + \n",
    "    \"entre os mesmos pre√ßos de a√ß√µes (stock) em 4 de janeiro?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zero_shot_agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pergunta que devemos nos fazer aqui √©: `como os agentes s√£o diferentes das cadeias?`\n",
    "\n",
    "Se observarmos a l√≥gica do agente e o prompt que acabamos de imprimir, veremos algumas diferen√ßas claras. `Primeiro`, temos as Tools inclu√≠das no prompt. Em `segundo` lugar, temos um processo de pensamento que antes era imediato em chains, mas agora envolve uma sequ√™ncia de `'pensamento'`, `'a√ß√£o'`, `'entrada de a√ß√£o'`, `'observa√ß√£o'`. <font color=\"red\">O que √© isso tudo?</font>\n",
    "\n",
    "\n",
    "Por enquanto, basta dizer que o `LLM` agora tem a capacidade de 'raciocinar' sobre a melhor forma de usar as Tools para resolver nossa consulta e pode combin√°-las de maneira inteligente com apenas uma breve descri√ß√£o de cada uma delas. Se voc√™ quiser saber mais sobre esse paradigma (`MRKL`) em detalhes, consulte este [paper](https://arxiv.org/pdf/2205.00445.pdf).\n",
    "\n",
    "\n",
    "\n",
    "Finalmente, vamos prestar aten√ß√£o ao `'agent_scratchpad'`. <font color=\"red\">O que √© aquilo?</font> Bem, √© onde estaremos anexando cada pensamento ou a√ß√£o que o agente j√° realizou. Desta forma, a cada momento, o agente saber√° o que descobriu e poder√° continuar seu processo de pensamento. Em outras palavras, depois de usar uma ferramenta, ela adiciona seus pensamentos e observa√ß√µes ao bloco de rascunho e continua a partir da√≠.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\">2. Tipo de Agente `Conversational React`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">O `agente zero shot` √© bem interessante mas, como dissemos antes, `n√£o tem mem√≥ria`. E se quisermos um assistente que se lembre de coisas sobre as quais conversamos e tamb√©m possa raciocinar sobre elas e usar ferramentas? Para isso temos o `agente conversational react`.\n",
    "\n",
    "Usaremos as mesmas ferramentas que especificamos anteriormente:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(\n",
    "    [\"llm-math\"], \n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "\n",
    "tools.append(sql_tool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">O tipo de mem√≥ria que est√° sendo usado aqui √© um `buffer de mem√≥ria simples` para nos permitir lembrar as etapas anteriores na cadeia de racioc√≠nio. Para mais informa√ß√µes sobre mem√≥ria veja a documenta√ß√£o do LangChain.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "\n",
    "conversational_agent = initialize_agent(\n",
    "    agent='conversational-react-description', \n",
    "    tools=tools, \n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    memory=memory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Stock DB\n",
      "Action Input: ABC stock prices on January 1st\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "ABC stock prices on January 1st\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT price FROM stocks WHERE stock_ticker = 'ABC' AND date = '2023-01-01' LIMIT 5;\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(200.0,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThe ABC stock price on January 1st was 200.0.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe ABC stock price on January 1st was 200.0.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: The ABC stock price on January 1st was 200.0.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Gastou um total de 1904 Tokens\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversational_agent, \n",
    "    \"Forne√ßa-me os pre√ßos das a√ß√µes da ABC em 1¬∫ de janeiro\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "TOOLS:\n",
      "------\n",
      "\n",
      "Assistant has access to the following tools:\n",
      "\n",
      "> Calculator: Useful for when you need to answer questions about math.\n",
      "> Stock DB: √ötil para quando voc√™ precisa responder a perguntas sobre a√ß√µes e seus pre√ßos.\n",
      "\n",
      "To use a tool, please use the following format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: the action to take, should be one of [Calculator, Stock DB]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: [your response here]\n",
      "```\n",
      "\n",
      "Begin!\n",
      "\n",
      "Previous conversation history:\n",
      "{chat_history}\n",
      "\n",
      "New input: {input}\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(conversational_agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">O assistente de conversa√ß√£o √© voltado para a conversa e tem um pouco mais de dificuldade em combinar uma combina√ß√£o complexa de Tools. Vamos ver o que acontece se tentarmos responder √† mesma pergunta que fizemos ao nosso agente anterior:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = count_tokens(\n",
    "    conversational_agent, \n",
    "    \"Qual √© a multiplica√ß√£o da rela√ß√£o entre a√ß√µes de pre√ßos de 'ABC' e 'XYZ' em 3 de janeiro e a rela√ß√£o entre os mesmos pre√ßos de a√ß√µes (stock) em 4 de janeiro?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, ele resolve o problema, mas de uma maneira diferente, usando a ferramenta SQL para resolver tamb√©m a matem√°tica. Interessante!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\">3. Tipo de Agente `React Docstore`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tipo de agente √© semelhante aos que vimos at√© agora, mas inclui a intera√ß√£o com um `docstore`. Ter√° √† sua disposi√ß√£o duas e apenas duas Tools: `'Search'` e `'Lookup'`.\n",
    "\n",
    "Com `'Search'` ele trar√° um artigo relevante e com `'Lookup'` o agente encontrar√° a informa√ß√£o certa no artigo. Isso provavelmente √© mais f√°cil de ver em um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import Wikipedia\n",
    "from langchain.agents.react.base import DocstoreExplorer\n",
    "\n",
    "docstore=DocstoreExplorer(Wikipedia())\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=docstore.search,\n",
    "        description='search wikipedia'\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Lookup\",\n",
    "        func=docstore.lookup,\n",
    "        description='lookup a term in wikipedia'\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "docstore_agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=\"react-docstore\", \n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Eu preciso pesquisar Arquimedes e encontrar sua famosa frase.\n",
      "Action: Search[Arquimedes]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mArchimedes of Syracuse (, ARK-ihm-EE-deez; c.‚Äâ287 ‚Äì c.‚Äâ212 BC) was an Ancient Greek mathematician, physicist, engineer, astronomer, and inventor from the ancient city of Syracuse in Sicily. Although few details of his life are known, he is regarded as one of the leading scientists in classical antiquity. Considered the greatest mathematician of ancient history, and one of the greatest of all time, Archimedes anticipated modern calculus and analysis by applying the concept of the infinitely small and the method of exhaustion to derive and rigorously prove a range of geometrical theorems. These include the area of a circle, the surface area and volume of a sphere, the area of an ellipse, the area under a parabola, the volume of a segment of a paraboloid of revolution, the volume of a segment of a hyperboloid of revolution, and the area of a spiral.Archimedes' other mathematical achievements include deriving an approximation of pi, defining and investigating the Archimedean spiral, and devising a system using exponentiation for expressing very large numbers. He was also one of the first to apply mathematics to physical phenomena, working on statics and hydrostatics. Archimedes' achievements in this area include a proof of the law of the lever, the widespread use of the concept of center of gravity, and the enunciation of the law of buoyancy or Archimedes' principle. He is also credited with designing innovative machines, such as his screw pump, compound pulleys, and defensive war machines to protect his native Syracuse from invasion.\n",
      "Archimedes died during the siege of Syracuse, when he was killed by a Roman soldier despite orders that he should not be harmed. Cicero describes visiting Archimedes' tomb, which was surmounted by a sphere and a cylinder that Archimedes requested be placed there to represent his mathematical discoveries.\n",
      "Unlike his inventions, Archimedes' mathematical writings were little known in antiquity. Mathematicians from Alexandria read and quoted him, but the first comprehensive compilation was not made until c.‚Äâ530 AD by Isidore of Miletus in Byzantine Constantinople, while commentaries on the works of Archimedes by Eutocius in the 6th century opened them to wider readership for the first time. The relatively few copies of Archimedes' written work that survived through the Middle Ages were an influential source of ideas for scientists during the Renaissance and again in the 17th century, while the discovery in 1906 of previously lost works by Archimedes in the Archimedes Palimpsest has provided new insights into how he obtained mathematical results.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m A famosa frase de Arquimedes √© \"Eureka! Eu encontrei-o!\"\n",
      "Action: Finish[\"Eureka! Eu encontrei-o!\"]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Gastou um total de 3624 Tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Qual √© a famosa frase do Arquimedes?',\n",
       " 'output': '\"Eureka! Eu encontrei-o!\"'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(docstore_agent, \"Qual √© a famosa frase do Arquimedes?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">N√£o imprimiremos o prompt aqui porque √© muito grande, mas voc√™ mesmo pode ver se quiser (j√° sabemos como fazer).</font>\n",
    "\n",
    "Resumindo, cont√©m v√°rios exemplos do loop `Question` > `Thought`> `Action` > `Observation`, que incluem as ferramentas `Search` e `Lookup`.\n",
    "\n",
    "Se voc√™ quiser aprender mais sobre essa abordagem, este √© o [paper](https://arxiv.org/pdf/2210.03629.pdf) do `ReAct`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\">4. Tipo de Agente `Self Ask with Search`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este √© o agente de primeira escolha a ser usado ao usar `LLMs` para extrair informa√ß√µes com um mecanismo de pesquisa (search engine). O agente far√° perguntas de acompanhamento e usar√° a funcionalidade de pesquisa para obter respostas intermedi√°rias que o ajudar√£o a chegar a uma resposta final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key='api_key')\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description='google search'\n",
    "    )\n",
    "]\n",
    "\n",
    "self_ask_with_search = initialize_agent(tools, llm, agent=\"self-ask-with-search\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">N√£o iremos interagir com este agente pois para isso precisar√≠amos de uma `chave serpapi`. No entanto, verificando o prompt, podemos ver alguns exemplos de como ele funciona:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali\n",
      "\n",
      "Question: When was the founder of craigslist born?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the founder of craigslist?\n",
      "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
      "Follow up: When was Craig Newmark born?\n",
      "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
      "So the final answer is: December 6, 1952\n",
      "\n",
      "Question: Who was the maternal grandfather of George Washington?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball\n",
      "\n",
      "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who is the director of Jaws?\n",
      "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
      "Follow up: Where is Steven Spielberg from?\n",
      "Intermediate answer: The United States.\n",
      "Follow up: Who is the director of Casino Royale?\n",
      "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
      "Follow up: Where is Martin Campbell from?\n",
      "Intermediate answer: New Zealand.\n",
      "So the final answer is: No\n",
      "\n",
      "Question: {input}\n",
      "Are followup questions needed here:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(self_ask_with_search.agent.llm_chain.prompt.template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
