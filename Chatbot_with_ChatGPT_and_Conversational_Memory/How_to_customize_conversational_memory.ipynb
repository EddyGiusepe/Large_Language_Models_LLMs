{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><font color=\"yellow\">Como personalizar a memória de conversação</font></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este estudo seguiremos o Tutorial do mesmo [LangChain 0.0.131](https://python.langchain.com/en/latest/modules/memory/examples/conversational_customization.html). A seguir aprenderemos a como customizar  uma `Memória Conversacional`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando a minha chave Key:  True\n"
     ]
    }
   ],
   "source": [
    "# Isto é quando usas o arquivo .env:\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "print('Carregando a minha chave Key: ', load_dotenv())\n",
    "Eddy_API_KEY_OpenAI = os.environ['OPENAI_API_KEY'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "llm = OpenAI(temperature=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefixo AI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira maneira de fazer isso é alterando o `prefixo AI` no resumo da conversa. Por padrão, isso é definido como `“AI”`, mas você pode definir como quiser. Observe que, se você alterar isso, também deverá alterar o `prompt usado` na cadeia para refletir essa alteração de nomenclatura. Vamos percorrer um exemplo disso no exemplo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui é por Default definido como \"AI\"\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Olá!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Olá! Como você está? Estou me sentindo bem hoje. Estou ansioso para ouvir sobre o que você tem a dizer.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Olá!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá!\n",
      "AI:  Olá! Como você está? Estou me sentindo bem hoje. Estou ansioso para ouvir sobre o que você tem a dizer.\n",
      "Human: Como está o tempo?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' O tempo está ótimo aqui! Está ensolarado e quente, com uma temperatura de aproximadamente 25 graus Celsius. A previsão é que continue assim por alguns dias.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Como está o tempo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora podemos substituí-lo e defini-lo como \"AI Assistant\"\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"O que se segue é uma conversa amigável entre um humano e uma IA.\n",
    "A IA é falante e fornece muitos detalhes específicos de seu contexto. Se a IA não souber a resposta\n",
    "para uma pergunta, ela diz com sinceridade que não sabe.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI Assistant:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"],\n",
    "    template=template\n",
    "                       )\n",
    "\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory(ai_prefix=\"AI Assistant\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mO que se segue é uma conversa amigável entre um humano e uma IA.\n",
      "A IA é falante e fornece muitos detalhes específicos de seu contexto. Se a IA não souber a resposta\n",
      "para uma pergunta, ela diz com sinceridade que não sabe.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Olá\n",
      "AI Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Olá! Meu nome é AI Assistant. Como posso ajudar?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Olá\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mO que se segue é uma conversa amigável entre um humano e uma IA.\n",
      "A IA é falante e fornece muitos detalhes específicos de seu contexto. Se a IA não souber a resposta\n",
      "para uma pergunta, ela diz com sinceridade que não sabe.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá\n",
      "AI Assistant:  Olá! Meu nome é AI Assistant. Como posso ajudar?\n",
      "Human: Como está o tempo?\n",
      "AI Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' O tempo está ótimo aqui! Está ensolarado e quente, com temperaturas na casa dos 25°C.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Como está o tempo?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefixo Humano"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima maneira de fazer isso é alterando o `prefixo Humano` no resumo da conversa. Por padrão, isso é definido como `“Humano”`, mas você pode definir como quiser. Observe que, se você alterar isso, também deverá alterar o `prompt` usado na cadeia para refletir essa alteração de nomenclatura. Vamos percorrer um exemplo disso no exemplo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora podemos substituí-lo e defini-lo como \"Amigo\"=\"Fiend\"\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"O que se segue é uma conversa amigável entre um humano e uma IA. A IA é falante e fornece muitos\n",
    "detalhes específicos de seu contexto. Se a IA não souber a resposta para uma pergunta, ela diz com sinceridade\n",
    "que não sabe.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Friend: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"],\n",
    "                        template=template\n",
    "                       )\n",
    "\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory(human_prefix=\"Friend\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mO que se segue é uma conversa amigável entre um humano e uma IA. A IA é falante e fornece muitos\n",
      "detalhes específicos de seu contexto. Se a IA não souber a resposta para uma pergunta, ela diz com sinceridade\n",
      "que não sabe.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Friend: Oi!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Olá! É um prazer conhecê-lo. Meu nome é AI-1. Como posso ajudar?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Oi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mO que se segue é uma conversa amigável entre um humano e uma IA. A IA é falante e fornece muitos\n",
      "detalhes específicos de seu contexto. Se a IA não souber a resposta para uma pergunta, ela diz com sinceridade\n",
      "que não sabe.\n",
      "\n",
      "Current conversation:\n",
      "Friend: Oi!\n",
      "AI:  Olá! É um prazer conhecê-lo. Meu nome é AI-1. Como posso ajudar?\n",
      "Friend: Como está o tempo?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' O tempo está ótimo aqui! Está ensolarado e quente, com temperaturas na faixa dos 25°C.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Como está o tempo?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e1f61a9d800d8d7b3909976e7b91d21ea533d3244cb881687ab788269722b79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
