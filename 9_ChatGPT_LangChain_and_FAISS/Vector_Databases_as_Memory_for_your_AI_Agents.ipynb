{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><font color=\"yellow\">Bancos de dados vetoriais como memória para seus agentes de IA</font></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">Data Scientist.: PhD.Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link de estudo:\n",
    "\n",
    "* https://medium.com/sopmac-ai/vector-databases-as-memory-for-your-ai-agents-986288530443"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolução do banco de dados — de relacional para vetorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A evolução do gerenciamento de dados viu uma mudança de bancos de dados relacionais (`SQL`), que são projetados para dados estruturados e dependem de esquemas fixos, para bancos de dados `NoSQL`, que oferecem mais flexibilidade na manipulação de dados não estruturados ou semiestruturados. `Os bancos de dados vetoriais representam o próximo passo nessa evolução`, fornecendo uma solução otimizada para gerenciar e consultar dados vetoriais de alta dimensão (ou seja, `Embeddings vetoriais`) , geralmente gerados por aplicativos de aprendizado de máquina e IA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Espaço de Alta Dimensão"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Embeddings vetoriais` são representações numéricas de objetos como: `palavras`, `imagens` ou outros pontos de dados em um espaço de alta dimensão.\n",
    "\n",
    "\n",
    "<font color=\"orange\">Um espaço de alta dimensão é um conceito matemático que representa um espaço com muitas dimensões, onde cada dimensão é um eixo separado ou feature dos dados. Em termos práticos, um espaço de alta dimensão é simplesmente uma maneira de descrever dados que possuem muitas features ou atributos.</font>\n",
    "\n",
    "\n",
    "Eles são gerados usando modelos de aprendizado de máquina ou redes neurais pré-treinadas. Esses Embeddings capturam as relações e similaridades entre os objetos, tornando mais fácil para um computador entender e processar os dados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Vetores, Embeddings e Dimensões simplificadas</font>\n",
    "\n",
    "\n",
    "Digamos que você tenha uma coleção de palavras e queira representá-las de uma forma que um computador possa entender e processar. Uma maneira de fazer isso é usando algo chamado `\"embeddings\"`.\n",
    "\n",
    "\n",
    "Pense nos Embeddings como uma forma de transformar palavras em pontos em um mapa. Cada palavra tem seu próprio lugar no mapa, e palavras similares ficam próximas umas das outras, enquanto palavras diferentes ficam distantes. Este `“mapa”` é como uma grade, mas com mais do que apenas duas direções (`cima/baixo` e `esquerda/direita`).\n",
    "\n",
    "\n",
    "As `“direções”` neste mapa são chamadas de `dimensões`. Cada dimensão é como uma característica ou característica diferente de uma palavra. `Por exemplo:` uma dimensão pode representar como é a palavra `\"feliz\"`, enquanto outra dimensão pode representar se é um animal ou não. <font color=\"yellow\">Quanto mais dimensões tivermos, mais características poderemos capturar sobre cada palavra.</font>\n",
    "\n",
    "Um `“vetor”` é como um conjunto de instruções que informa como chegar à localização de uma palavra no mapa. Ele contém números para cada dimensão que o ajudam a encontrar o local exato da palavra. Quando falamos de `“Embeddings de vetores”`, estamos falando desses conjuntos de números que representam a localização das palavras em nosso mapa multidimensional.\n",
    "\n",
    "\n",
    "Então, em termos simples, os `Embeddings` são uma forma de transformar palavras em pontos em um mapa com muitas direções (dimensões), e os vetores são os conjuntos de números que nos ajudam a encontrar a localização de cada palavra nesse mapa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bancos de dados vetoriais\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bancos de dados vetoriais, também conhecidos como `bancos de dados de pesquisa de similaridade` ou `bancos de dados de pesquisa do vizinho mais próximo`, são bancos de dados especializados projetados para armazenar e consultar Embeddings de vetores de forma eficiente. Eles permitem que você execute operações como encontrar os itens mais similares a um determinado vetor ou pesquisar itens que atendam a critérios de similaridade específicos.\n",
    "\n",
    "Os bancos de dados tradicionais não são otimizados para essas tarefas, e é por isso que os `bancos de dados vetoriais` se tornaram cada vez mais populares."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como integrar bancos de dados vetoriais usando Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que definimos alguma teoria por trás deste tópico, vamos fazer a transição para a aplicação prática de `bancos de dados vetoriais` com `Pinecone`, `Chroma` e `LangChain` — todos usando `Embeddings de vetores OpenAI`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\">API PINECONE</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código demonstra como usar o `Pinecone` e o `OpenAI` para realizar uma pesquisa de similaridade em um conjunto de documentos usando Embeddings da OpenAI.\n",
    "\n",
    "\n",
    "```\n",
    "!pip install pinecone-client openai\n",
    "```\n",
    "\n",
    "Link para mais detalhes: [pinecone.io](https://www.pinecone.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando a minha chave Key:  True\n"
     ]
    }
   ],
   "source": [
    "# Isto é quando usas o arquivo .env:\n",
    "import openai \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "print('Carregando a minha chave Key: ', load_dotenv())\n",
    "Eddy_API_KEY_OpenAI = os.environ['OPENAI_API_KEY']  \n",
    "Eddy_API_KEY_Cohere = os.environ[\"COHERE_API_KEY\"]\n",
    "Eddy_API_KEY_HuggingFace = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "Eddy_API_KEY_SerpApi = os.environ[\"SERPAPI_API_KEY\"]\n",
    "Eddy_API_KEY_WolframAlpha = os.environ[\"WOLFRAM_ALPHA_APPID\"]\n",
    "\n",
    "Eddy_API_KEY_pinecone = os.environ[\"PINECONE_API_KEY\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\">CHROMA — Opção de armazenamento efêmero</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código a seguir demonstra como usar `ChromaDB` e `OpenAI` para realizar uma pesquisa de similaridade em um conjunto de documentos.\n",
    "\n",
    "```\n",
    "!pip install chromadb openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import chromadb\n",
    "import openai\n",
    "\n",
    "OPENAI_API_KEY = Eddy_API_KEY_OpenAI\n",
    "\n",
    "\n",
    "client = chromadb.Client()\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(prompt):\n",
    "    res = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                       messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                                      )\n",
    "    \n",
    "    return res['choices'][0]['message']['content'].strip()\n",
    "\n",
    "def get_ada_embedding(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return openai.Embedding.create(input=text, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_TABLE_NAME = \"chroma-openai\"\n",
    "\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(api_key=OPENAI_API_KEY,\n",
    "                                                        model_name=\"text-embedding-ada-002\"\n",
    "                                                       )\n",
    "\n",
    "collection = client.create_collection(CHROMA_TABLE_NAME, embedding_function=openai_ef)\n",
    "\n",
    "\n",
    "texts = [\n",
    "        \"Agentes de AI como funcionários virtuais são o futuro.\",\n",
    "        \"Bancos de dados vetoriais são o futuro.\",\n",
    "        \"AGI não está aqui... ainda.\"\n",
    "    ]\n",
    "\n",
    "for loopIndex, text in enumerate(texts, start=1):\n",
    "  collection.add(embeddings=get_ada_embedding(text), metadatas=[{\"text\": text}], ids=[\"test-openai-\"+str(loopIndex)]) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['test-openai-1', 'test-openai-2', 'test-openai-3']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[None, None, None]],\n",
       " 'metadatas': [[{'text': 'Agentes de AI como funcionários virtuais são o futuro.'},\n",
       "   {'text': 'Bancos de dados vetoriais são o futuro.'},\n",
       "   {'text': 'AGI não está aqui... ainda.'}]],\n",
       " 'distances': [[0.14552298188209534, 0.34075218439102173, 0.4094182848930359]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text = \"Os agentes de AI são o futuro?\"\n",
    "\n",
    "\n",
    "results = collection.query(query_embeddings=get_ada_embedding(query_text),\n",
    "                           n_results=3\n",
    "                          )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ids\": [\n",
      "    [\n",
      "      \"test-openai-1\",\n",
      "      \"test-openai-2\",\n",
      "      \"test-openai-3\"\n",
      "    ]\n",
      "  ],\n",
      "  \"embeddings\": null,\n",
      "  \"documents\": [\n",
      "    [\n",
      "      null,\n",
      "      null,\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"metadatas\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Agentes de AI como funcion\\u00e1rios virtuais s\\u00e3o o futuro.\"\n",
      "      },\n",
      "      {\n",
      "        \"text\": \"Bancos de dados vetoriais s\\u00e3o o futuro.\"\n",
      "      },\n",
      "      {\n",
      "        \"text\": \"AGI n\\u00e3o est\\u00e1 aqui... ainda.\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"distances\": [\n",
      "    [\n",
      "      0.14552298188209534,\n",
      "      0.34075218439102173,\n",
      "      0.4094182848930359\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(results, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection(name=\"chroma-openai\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Instale as bibliotecas necessárias: `chromadb` e `openai`.\n",
    "\n",
    "2. Configure a chave de API OpenAI.\n",
    "\n",
    "3. Crie uma instância do `cliente ChromaDB`.\n",
    "\n",
    "4. Defina uma função `complete` para gerar uma resposta do modelo `GPT-3.5-turbo`, dado um `prompt`.\n",
    "\n",
    "5. Defina uma função `get_ada_embedding` para obter Embeddings para texto de entrada usando o modelo `\"text-embedding-ada-002\"` da `OpenAI`.\n",
    "\n",
    "6. Defina o nome da `tabela ChromaDB`.\n",
    "\n",
    "7. Importe os utilitários necessários da `biblioteca chromadb`.\n",
    "\n",
    "8. Crie um objeto de função de Embeddings OpenAI usando a chave de API OpenAI e o modelo `“text-embedding-ada-002”`.\n",
    "\n",
    "9. Crie uma `coleção ChromaDB` com o nome da tabela e a função de Embedding especificados.\n",
    "\n",
    "10. Defina uma `lista de textos` para servir como documentos a serem `indexados e pesquisados`.\n",
    "\n",
    "11. Percorra os textos, obtenha Embeddings usando a função `get_ada_embedding` e adicione-os à coleção `ChromaDB` junto com metadados (`text content`) e um identificador exclusivo.\n",
    "\n",
    "12. Defina o texto da query para a pesquisa de similaridade.\n",
    "\n",
    "13. Realize uma pesquisa de similaridade na `coleção ChromaDB` usando os embeddings obtidos do texto da consulta e `recupere os 3 principais resultados mais similares`.\n",
    "\n",
    "14. Imprima os resultados da pesquisa em uma representação `JSON` formatada.\n",
    "\n",
    "15. Exclua a coleção ChromaDB.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Em resumo, o código acima demonstra como usar `ChromaDB` e `OpenAI` para realizar uma pesquisa de similaridade em um conjunto de documentos, obtendo embeddings do modelo `OpenAI` `“text-embedding-ada-002”` e usando ChromaDB para armazenar e consultar esses embeddings.</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\">LANGCHAIN ​​VectorStore</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código a seguir instala as bibliotecas necessárias e demonstra como usar dois `diferentes vector stores` (`Chroma` e `Pinecone`) para realizar pesquisas de similaridade em um conjunto de documentos usando os `Embeddings da OpenAI`.\n",
    "\n",
    "```\n",
    "!pip install pinecone-client chromadb openai langchain tiktoken\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = Eddy_API_KEY_pinecone\n",
    "#PINECONE_ENV = \"YOUR_PINECONE_ENVIRONMENT\"\n",
    "OPENAI_API_KEY = Eddy_API_KEY_OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "def get_ada_embedding(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return openai.Embedding.create(input=text, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "        \"Agentes de AI como funcionários virtuais são o futuro.\",\n",
    "        \"Bancos de dados vetoriais são o futuro.\",\n",
    "        \"AGI não está aqui... ainda.\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Agentes de AI como funcionários virtuais são o futuro.', metadata={}), Document(page_content='Bancos de dados vetoriais são o futuro.', metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "CHROMA_TABLE_NAME = \"YOUR_CHROMA_TABLE_NAME\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "query = \"Qual é o futuro?\"\n",
    "\n",
    "\n",
    "docsearch = Chroma.from_texts(texts, embeddings)\n",
    "docs = docsearch.similarity_search(query, k=2)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "\n",
    "\n",
    "PINECONE_TABLE_NAME = \"YOUR_PINECONE_INDEX_NAME\"\n",
    "\n",
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "query = \"Qual é o futuro?\"\n",
    "\n",
    "# docsearch = Pinecone.from_texts(texts, embeddings, index_name=PINECONE_TABLE_NAME)\n",
    "# docs = docsearch.similarity_search(query, k=2)\n",
    "# print(docs)\n",
    "\n",
    "docsearch = Pinecone.from_existing_index(PINECONE_TABLE_NAME, embeddings)\n",
    "docs = docsearch.similarity_search(query, k=2)\n",
    "print(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
