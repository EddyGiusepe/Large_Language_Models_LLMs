{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><font color=\"yellow\">Quatro maneiras de Question-Answering in LangChain</font></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este script est√° baseado nos trabalhos da [Sophia Yang]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualizando"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converse com seus longos documentos `PDF`: load_qa_chain, RetrievalQA, VectorstoreIndexCreator, ConversationalRetrievalChain.\n",
    "\n",
    "\n",
    "Voc√™ est√° interessado em conversar com seus pr√≥prios documentos, seja um `arquivo de texto`, um `PDF` ou um `site`? O `LangChain` torna mais f√°cil para voc√™ responder a perguntas com seus documentos. Mas voc√™ sabia que existem pelo menos `4` maneiras de responder a perguntas no LangChain? Nesta postagem do blog, exploraremos quatro maneiras diferentes de responder a perguntas e as v√°rias op√ß√µes que voc√™ pode considerar para seus casos de uso.\n",
    "\n",
    "S√≥ lembrando que √© `LangChain`, na opini√£o de `Sophia Yang`, √© a maneira mais f√°cil de interagir com modelos de linguagem e criar aplicativos. √â uma ferramenta de c√≥digo aberto que envolve muitos `LLMs` e ferramentas. \n",
    "\n",
    "Ok, agora vamos come√ßar a responder perguntas em documentos externos.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurando a API da OpenAI e importando as Bibliotecas necess√°rias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que a [API OpenAI](https://platform.openai.com/account) n√£o √© gratuita. Voc√™ precisar√° configurar as informa√ß√µes de cobran√ßa para poder usar a `API OpenAI`. Como alternativa, voc√™ pode usar modelos do `HuggingFace Hub` ou de outros lugares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install langchain==0.0.137 openai chromadb tiktoken pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando a minha chave Key:  True\n"
     ]
    }
   ],
   "source": [
    "# Isto √© quando usas o arquivo .env:\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "print('Carregando a minha chave Key: ', load_dotenv())\n",
    "Eddy_API_KEY_OpenAI = os.environ['OPENAI_API_KEY'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA # Tem que atualizar --> pip install langchai==0.0.137\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando Documentos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `LangChain` suporta muitos [carregadores de documentos](https://python.langchain.com/en/latest/modules/indexes/document_loaders.html), como `Notion`, `YouTube` e `Figma`. Neste exemplo, gostaria de conversar com meu arquivo `PDF`. Assim, usei o `PyPDFLoader` para carregar meu arquivo.\n",
    "\n",
    "Eu recomendo usar um PDF pequeno. Eu usei, s√≥ para demonstra√ß√£o mesmo, um boleto de pagamento da minha conta de energia que cont√©m apenas uma p√°gina (voc√™ pode usar qualquer outro documento). Meu boleto cont√©m certas entidades e em base a elas farei certas perguntas! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "O que aconteceu quando o tijolo caiu do c√©u? Ele deu um tijolo no ch√£o.\n"
     ]
    }
   ],
   "source": [
    "# Verificamos nosso Modelo Instanciado:\n",
    "\n",
    "llm = OpenAI()\n",
    "print(llm(\"Conte-me uma piada.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando meu documento (Boleto de energia):\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./Karina_boleto_FACULDADE.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=' \\nRECIBO DO PAGADOR\\nBenefici√°rio\\nUNIFRAN - GRADUA√á√ÉO EAD - CNPJ: 046.722.831/0001-78 \\nAv. Dr. Armando Salles Oliveira - Franca/SPAg√™ncia/C√≥d. Benefici√°rio\\n3393 - 6 / 0001544 - PData do Documento\\n02/03/2023Vencimento\\n27/03/2023\\nPagador\\nKARINA GON√áALVES SOARESN√∫mero Documento\\n23103/06Nosso N√∫mero\\n19/00236419200-6Valor do Documento\\nR$ 551,26\\nInstru√ß√µes: (Todas as informa√ß√µes deste bloqueto s√£o de exclusiva responsabilidade do benefici√°rio)\\n* SR. CAIXA NAO RECEBER APOS VENCIMENTO; \\n* DESCONTO DE R$ 320,43 ATE 07/03/23; R$ 289,64 ATE 27/03/23; \\n* (3A CST EM CI√äNCIA DE DADOS) - RGM:22-30419841 \\nAutentica√ß√£o Mec√¢nica\\n237-2 23793.39316 90023.641922 00000.154401 2 93020000055126\\nLocal de Pagamento\\nPag√°vel preferencialmente nas ag√™ncias BRADESCOVencimento\\n27/03/2023\\nBenefici√°rio\\nUNIFRAN - GRADUA√á√ÉO EAD - CNPJ: 046.722.831/0001-78 - Av. Dr. Armando Salles Oliveira - Franca/SPAg√™ncia/C√≥digo Benefici√°rio\\n3393 - 6 / 0001544 - P\\nData do Documento\\n02/03/2023N¬∞. do Documento\\n23103/06Esp√©cie doc.\\nDMAceite\\nNData Processamento\\n02/03/2023Nosso N√∫mero\\n19/00236419200-6\\nUso do Banco Carteira\\n19Esp√©cie Moeda\\nREALQuantidade (X) Valor 1 (=) Valor do Documento\\nR$ 551,26\\nInstru√ß√µes: (Todas as informa√ß√µes deste bloqueto s√£o de exclusiva responsabilidade do benefici√°rio)\\n *** VALORES EXPRESSOS EM REAIS ***\\n* SR. CAIXA NAO RECEBER APOS VENCIMENTO; \\n* DESCONTO DE R$ 320,43 ATE 07/03/23; R$ 289,64 ATE 27/03/23; \\n* (3A CST EM CI√äNCIA DE DADOS) - RGM:22-30419841 2 (-) Descontos/Abatimento\\n3 (-) Outras Dedu√ß√µes\\n4 (+) Mora / Multa\\n5 (+) Outros Acr√©scimos\\n6 (=) Valor Cobrado\\nPagador: KARINA GON√áALVES SOARES\\nRua H√©lio Soares,115 - Pr√≥ximo ao UP.\\n29062140 Pontal de Camburi Vit√≥ria Ficha de Compensa√ß√£o\\nAutentica√ß√£o Mec√¢nica', metadata={'source': './Karina_boleto_FACULDADE.pdf', 'page': 0})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M√©todo 1: <font color=\"red\">load_qa_chain</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`load_qa_chain` fornece a interface mais gen√©rica para responder a perguntas. Ele carrega uma cadeia que voc√™ pode fazer `QA` para seus documentos de entrada e usa TODO o texto nos documentos.\n",
    "\n",
    "`chain_type=\"stuff\"` n√£o funcionar√° porque o n√∫mero de tokens excede o limite. Podemos tentar outros tipos de cadeia como `\"map_reduce\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' O nome do pagador √© KARINA GON√áALVES SOARES.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "\n",
    "chain = load_qa_chain(llm=OpenAI(),\n",
    "                      chain_type=\"map_reduce\"\n",
    "                     )\n",
    "\n",
    "\n",
    "query = \"Qual √© o nome do pagador?\"\n",
    "\n",
    "chain.run(input_documents=documents,\n",
    "          question=query\n",
    "         )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Ele tamb√©m permite que voc√™ fa√ßa QA em um conjunto de documentos:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Para v√°rios Documentos:\n",
    "# loaders = [....]\n",
    "# documents = []\n",
    "# for loader in loaders:\n",
    "#     documents.extend(loader.load())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î Mas e se meu documento for muito longo e ultrapassar o limite de token?\n",
    "\n",
    "Existem duas maneiras de corrigi-lo:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\">Solu√ß√£o 1: Tipo de Cadeia (chain)</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O padr√£o `chain_type=\"stuff\"` usa `TODO` o texto dos documentos no prompt. Se voc√™ tiver um arquivo muito grande (`tal como fez Sophia Yang, com um PDF de `50` p√°ginas`) n√£o funcionar√° porque excede o `limite de token` e causa erros de limita√ß√£o de taxa. √â por isso que para o exemplo da Sophia Yang, ela teve que usar outro tipo de cadeia, por exemplo `\"map_reduce\"`. \n",
    "\n",
    "A seguir vamos estudar outros tipos de cadeias:\n",
    "\n",
    "ü§© `map_reduce:` Separa os textos em lotes (<font color=\"red\">por exemplo</font>, voc√™ pode definir o tamanho do lote em `llm=OpenAI(batch_size=5)`), alimenta cada lote com a pergunta para o `LLM` separadamente e apresenta a resposta final com base nas respostas de cada lote.\n",
    "\n",
    "ü§© `refine:` Separa os textos em lotes, alimenta o primeiro lote para o LLM e alimenta a resposta e o segundo lote para o LLM. Ele refina a resposta passando por todos os lotes.\n",
    "\n",
    "ü§© `map-rerank:` ele separa os textos em lotes, alimenta cada lote para o LLM, retorna uma pontua√ß√£o de como responde completamente √† pergunta e apresenta a resposta final com base nas respostas com pontua√ß√£o mais alta de cada lote."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\">Solu√ß√£o 2: Recupera√ß√£o QA (`RetrievalQA`)</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um problema com o uso de `TODO` o texto √© que pode ser `muito caro` porque voc√™ est√° alimentando todos os textos para a `API OpenAI` e a `API` √© cobrada pelo n√∫mero de tokens. Uma solu√ß√£o melhor √© recuperar os blocos (`chunks`) de texto relevantes primeiro e usar apenas os blocos de texto relevantes no modelo de linguagem. A seguir, examinarei os detalhes do `RetrievalQA`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M√©todo 2: <font color=\"red\">RetrievalQA</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
